{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to load the dataset\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    fish_files = np.array(data['filenames'])\n",
    "    fish_target = np_utils.to_categorical(np.array(data['target']), 8)\n",
    "    return fish_files,fish_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3777 images in training dataset\n",
      "There are 13153 images in the training set\n"
     ]
    }
   ],
   "source": [
    "#let's load the training-data\n",
    "train_files, train_targets = load_dataset('data/train')\n",
    "\n",
    "#let's load the teting-data\n",
    "test_files, _ = load_dataset('data/test')\n",
    "\n",
    "#print the number of samples in test and trainin sets\n",
    "print (\"There are %d images in training dataset\"%len(train_files))\n",
    "print (\"There are %d images in the training set\"%len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "\n",
    "#converting image to tensor\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image\n",
    "    img = image.load_img(img_path, target_size=(224,224))\n",
    "    #convering the image to 3-D tensor with shape (224,224,3)\n",
    "    x = image.img_to_array(img)\n",
    "    #convert 3D tensor to 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 13153/13153 [02:25<00:00, 90.37it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True \n",
    "\n",
    "#preprocessing the data\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3777/3777 [01:51<00:00, 34.01it/s]\n"
     ]
    }
   ],
   "source": [
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3777, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "#shape of the tensor\n",
    "print(np.shape(train_tensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's have the Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 223, 223, 16)      208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 110, 110, 32)      2080      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 264       \n",
      "=================================================================\n",
      "Total params: 2,552\n",
      "Trainable params: 2,552\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's have a Benchmark model\n",
    "\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "benchmark = Sequential()\n",
    "\n",
    "# model Convolution layer\n",
    "benchmark.add(Conv2D(filters=16,kernel_size=2,strides=1,activation='relu',input_shape=(224,224,3)))\n",
    "# Max Pooling layer to reduce the dimensionality\n",
    "benchmark.add(MaxPooling2D(pool_size=2,strides=2))\n",
    "#Dropout layer, for turning off each node with the probability of 0.3\n",
    "benchmark.add(Dropout(0.3))\n",
    "benchmark.add(Conv2D(filters=32, kernel_size=2,strides=1,activation='relu'))\n",
    "benchmark.add(Dropout(0.3))\n",
    "benchmark.add(GlobalAveragePooling2D())\n",
    "#A fully connected dense layer with 8 nodes (no of classes of fish)\n",
    "benchmark.add(Dense(8,activation='softmax'))\n",
    "benchmark.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3021 samples, validate on 756 samples\n",
      "Epoch 1/5\n",
      "3021/3021 [==============================] - ETA: 15:33 - loss: 2.0585 - acc: 0.10 - ETA: 5:10 - loss: 2.0351 - acc: 0.2000 - ETA: 3:53 - loss: 2.0143 - acc: 0.275 - ETA: 2:35 - loss: 1.9812 - acc: 0.333 - ETA: 1:56 - loss: 1.9428 - acc: 0.381 - ETA: 1:32 - loss: 1.9142 - acc: 0.395 - ETA: 1:17 - loss: 1.9024 - acc: 0.408 - ETA: 1:05 - loss: 1.8844 - acc: 0.410 - ETA: 57s - loss: 1.8617 - acc: 0.418 - ETA: 50s - loss: 1.8498 - acc: 0.41 - ETA: 45s - loss: 1.8321 - acc: 0.42 - ETA: 41s - loss: 1.8082 - acc: 0.42 - ETA: 37s - loss: 1.7973 - acc: 0.42 - ETA: 34s - loss: 1.7919 - acc: 0.42 - ETA: 31s - loss: 1.7737 - acc: 0.43 - ETA: 29s - loss: 1.7681 - acc: 0.43 - ETA: 27s - loss: 1.7688 - acc: 0.43 - ETA: 25s - loss: 1.7714 - acc: 0.42 - ETA: 23s - loss: 1.7697 - acc: 0.42 - ETA: 22s - loss: 1.7659 - acc: 0.42 - ETA: 21s - loss: 1.7620 - acc: 0.42 - ETA: 19s - loss: 1.7532 - acc: 0.42 - ETA: 18s - loss: 1.7437 - acc: 0.42 - ETA: 17s - loss: 1.7479 - acc: 0.42 - ETA: 16s - loss: 1.7415 - acc: 0.43 - ETA: 16s - loss: 1.7429 - acc: 0.42 - ETA: 15s - loss: 1.7431 - acc: 0.42 - ETA: 14s - loss: 1.7317 - acc: 0.43 - ETA: 13s - loss: 1.7198 - acc: 0.43 - ETA: 13s - loss: 1.7180 - acc: 0.43 - ETA: 12s - loss: 1.7129 - acc: 0.43 - ETA: 11s - loss: 1.7076 - acc: 0.43 - ETA: 11s - loss: 1.7042 - acc: 0.43 - ETA: 10s - loss: 1.7066 - acc: 0.43 - ETA: 10s - loss: 1.7073 - acc: 0.43 - ETA: 9s - loss: 1.7009 - acc: 0.4364 - ETA: 9s - loss: 1.6977 - acc: 0.435 - ETA: 9s - loss: 1.6914 - acc: 0.435 - ETA: 8s - loss: 1.6954 - acc: 0.434 - ETA: 8s - loss: 1.6927 - acc: 0.434 - ETA: 7s - loss: 1.6902 - acc: 0.434 - ETA: 7s - loss: 1.6913 - acc: 0.433 - ETA: 7s - loss: 1.6904 - acc: 0.435 - ETA: 6s - loss: 1.6846 - acc: 0.438 - ETA: 6s - loss: 1.6830 - acc: 0.439 - ETA: 6s - loss: 1.6782 - acc: 0.440 - ETA: 5s - loss: 1.6811 - acc: 0.438 - ETA: 5s - loss: 1.6753 - acc: 0.438 - ETA: 5s - loss: 1.6703 - acc: 0.441 - ETA: 5s - loss: 1.6697 - acc: 0.441 - ETA: 4s - loss: 1.6670 - acc: 0.443 - ETA: 4s - loss: 1.6646 - acc: 0.444 - ETA: 4s - loss: 1.6622 - acc: 0.444 - ETA: 4s - loss: 1.6583 - acc: 0.444 - ETA: 3s - loss: 1.6591 - acc: 0.444 - ETA: 3s - loss: 1.6521 - acc: 0.447 - ETA: 3s - loss: 1.6509 - acc: 0.447 - ETA: 3s - loss: 1.6487 - acc: 0.448 - ETA: 3s - loss: 1.6481 - acc: 0.449 - ETA: 2s - loss: 1.6494 - acc: 0.448 - ETA: 2s - loss: 1.6446 - acc: 0.450 - ETA: 2s - loss: 1.6421 - acc: 0.450 - ETA: 2s - loss: 1.6420 - acc: 0.451 - ETA: 2s - loss: 1.6427 - acc: 0.450 - ETA: 1s - loss: 1.6409 - acc: 0.450 - ETA: 1s - loss: 1.6415 - acc: 0.448 - ETA: 1s - loss: 1.6402 - acc: 0.449 - ETA: 1s - loss: 1.6384 - acc: 0.450 - ETA: 1s - loss: 1.6395 - acc: 0.450 - ETA: 1s - loss: 1.6421 - acc: 0.450 - ETA: 0s - loss: 1.6440 - acc: 0.447 - ETA: 0s - loss: 1.6445 - acc: 0.447 - ETA: 0s - loss: 1.6452 - acc: 0.446 - ETA: 0s - loss: 1.6442 - acc: 0.446 - ETA: 0s - loss: 1.6409 - acc: 0.448 - ETA: 0s - loss: 1.6387 - acc: 0.450 - 12s 4ms/step - loss: 1.6396 - acc: 0.4492 - val_loss: 1.6088 - val_acc: 0.4643\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60876, saving model to saved_models/weights.best.benchmark.hdf5\n",
      "Epoch 2/5\n",
      "3021/3021 [==============================] - ETA: 4s - loss: 1.4831 - acc: 0.550 - ETA: 4s - loss: 1.5148 - acc: 0.466 - ETA: 4s - loss: 1.5064 - acc: 0.460 - ETA: 4s - loss: 1.5819 - acc: 0.435 - ETA: 4s - loss: 1.5883 - acc: 0.444 - ETA: 4s - loss: 1.6082 - acc: 0.440 - ETA: 4s - loss: 1.6286 - acc: 0.434 - ETA: 4s - loss: 1.6472 - acc: 0.430 - ETA: 4s - loss: 1.6358 - acc: 0.444 - ETA: 4s - loss: 1.6327 - acc: 0.439 - ETA: 4s - loss: 1.6174 - acc: 0.440 - ETA: 4s - loss: 1.5995 - acc: 0.452 - ETA: 4s - loss: 1.6071 - acc: 0.450 - ETA: 4s - loss: 1.6098 - acc: 0.446 - ETA: 4s - loss: 1.6211 - acc: 0.444 - ETA: 3s - loss: 1.6193 - acc: 0.445 - ETA: 3s - loss: 1.6106 - acc: 0.447 - ETA: 3s - loss: 1.6212 - acc: 0.437 - ETA: 3s - loss: 1.6224 - acc: 0.440 - ETA: 3s - loss: 1.6151 - acc: 0.444 - ETA: 3s - loss: 1.6026 - acc: 0.448 - ETA: 3s - loss: 1.5993 - acc: 0.454 - ETA: 3s - loss: 1.6173 - acc: 0.448 - ETA: 3s - loss: 1.6148 - acc: 0.448 - ETA: 3s - loss: 1.6054 - acc: 0.452 - ETA: 3s - loss: 1.5953 - acc: 0.454 - ETA: 3s - loss: 1.5914 - acc: 0.456 - ETA: 3s - loss: 1.5957 - acc: 0.457 - ETA: 3s - loss: 1.5991 - acc: 0.457 - ETA: 3s - loss: 1.6039 - acc: 0.452 - ETA: 3s - loss: 1.6064 - acc: 0.453 - ETA: 3s - loss: 1.6036 - acc: 0.452 - ETA: 2s - loss: 1.6063 - acc: 0.452 - ETA: 2s - loss: 1.6118 - acc: 0.448 - ETA: 2s - loss: 1.6076 - acc: 0.447 - ETA: 2s - loss: 1.6100 - acc: 0.445 - ETA: 2s - loss: 1.6088 - acc: 0.446 - ETA: 2s - loss: 1.6091 - acc: 0.448 - ETA: 2s - loss: 1.6056 - acc: 0.448 - ETA: 2s - loss: 1.6034 - acc: 0.449 - ETA: 2s - loss: 1.5981 - acc: 0.452 - ETA: 2s - loss: 1.6004 - acc: 0.451 - ETA: 2s - loss: 1.5996 - acc: 0.451 - ETA: 2s - loss: 1.6008 - acc: 0.451 - ETA: 2s - loss: 1.5987 - acc: 0.452 - ETA: 2s - loss: 1.5998 - acc: 0.452 - ETA: 1s - loss: 1.6010 - acc: 0.450 - ETA: 1s - loss: 1.6022 - acc: 0.451 - ETA: 1s - loss: 1.5992 - acc: 0.452 - ETA: 1s - loss: 1.5982 - acc: 0.451 - ETA: 1s - loss: 1.5950 - acc: 0.452 - ETA: 1s - loss: 1.5917 - acc: 0.453 - ETA: 1s - loss: 1.5883 - acc: 0.456 - ETA: 1s - loss: 1.5884 - acc: 0.457 - ETA: 1s - loss: 1.5931 - acc: 0.455 - ETA: 1s - loss: 1.5904 - acc: 0.455 - ETA: 1s - loss: 1.5969 - acc: 0.454 - ETA: 1s - loss: 1.5980 - acc: 0.453 - ETA: 1s - loss: 1.5974 - acc: 0.452 - ETA: 1s - loss: 1.5962 - acc: 0.451 - ETA: 1s - loss: 1.5934 - acc: 0.452 - ETA: 0s - loss: 1.5945 - acc: 0.453 - ETA: 0s - loss: 1.5951 - acc: 0.452 - ETA: 0s - loss: 1.5950 - acc: 0.452 - ETA: 0s - loss: 1.5950 - acc: 0.451 - ETA: 0s - loss: 1.5918 - acc: 0.452 - ETA: 0s - loss: 1.5892 - acc: 0.453 - ETA: 0s - loss: 1.5906 - acc: 0.453 - ETA: 0s - loss: 1.5930 - acc: 0.451 - ETA: 0s - loss: 1.5930 - acc: 0.452 - ETA: 0s - loss: 1.5957 - acc: 0.451 - ETA: 0s - loss: 1.5939 - acc: 0.452 - ETA: 0s - loss: 1.5939 - acc: 0.453 - ETA: 0s - loss: 1.5945 - acc: 0.452 - ETA: 0s - loss: 1.5932 - acc: 0.453 - ETA: 0s - loss: 1.5941 - acc: 0.453 - 6s 2ms/step - loss: 1.5944 - acc: 0.4528 - val_loss: 1.5988 - val_acc: 0.4643\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.60876 to 1.59879, saving model to saved_models/weights.best.benchmark.hdf5\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3021/3021 [==============================] - ETA: 4s - loss: 1.9612 - acc: 0.400 - ETA: 5s - loss: 1.8048 - acc: 0.400 - ETA: 5s - loss: 1.7135 - acc: 0.420 - ETA: 5s - loss: 1.6930 - acc: 0.414 - ETA: 5s - loss: 1.6994 - acc: 0.394 - ETA: 4s - loss: 1.6402 - acc: 0.431 - ETA: 4s - loss: 1.6342 - acc: 0.434 - ETA: 4s - loss: 1.6480 - acc: 0.440 - ETA: 4s - loss: 1.6235 - acc: 0.447 - ETA: 4s - loss: 1.6064 - acc: 0.450 - ETA: 4s - loss: 1.6033 - acc: 0.447 - ETA: 4s - loss: 1.6030 - acc: 0.443 - ETA: 4s - loss: 1.5811 - acc: 0.454 - ETA: 4s - loss: 1.5927 - acc: 0.444 - ETA: 4s - loss: 1.5980 - acc: 0.439 - ETA: 3s - loss: 1.5936 - acc: 0.435 - ETA: 3s - loss: 1.6005 - acc: 0.431 - ETA: 3s - loss: 1.6228 - acc: 0.422 - ETA: 3s - loss: 1.6200 - acc: 0.428 - ETA: 3s - loss: 1.6168 - acc: 0.429 - ETA: 3s - loss: 1.6140 - acc: 0.429 - ETA: 3s - loss: 1.6123 - acc: 0.432 - ETA: 3s - loss: 1.6174 - acc: 0.433 - ETA: 3s - loss: 1.6187 - acc: 0.427 - ETA: 3s - loss: 1.6181 - acc: 0.427 - ETA: 3s - loss: 1.6134 - acc: 0.431 - ETA: 3s - loss: 1.6027 - acc: 0.436 - ETA: 3s - loss: 1.6020 - acc: 0.435 - ETA: 3s - loss: 1.6028 - acc: 0.434 - ETA: 2s - loss: 1.6037 - acc: 0.434 - ETA: 2s - loss: 1.5982 - acc: 0.437 - ETA: 2s - loss: 1.6009 - acc: 0.435 - ETA: 2s - loss: 1.5966 - acc: 0.436 - ETA: 2s - loss: 1.5894 - acc: 0.439 - ETA: 2s - loss: 1.5848 - acc: 0.439 - ETA: 2s - loss: 1.5844 - acc: 0.439 - ETA: 2s - loss: 1.5789 - acc: 0.443 - ETA: 2s - loss: 1.5820 - acc: 0.444 - ETA: 2s - loss: 1.5792 - acc: 0.444 - ETA: 2s - loss: 1.5762 - acc: 0.445 - ETA: 2s - loss: 1.5788 - acc: 0.443 - ETA: 2s - loss: 1.5770 - acc: 0.444 - ETA: 2s - loss: 1.5804 - acc: 0.443 - ETA: 2s - loss: 1.5786 - acc: 0.444 - ETA: 2s - loss: 1.5838 - acc: 0.443 - ETA: 1s - loss: 1.5770 - acc: 0.446 - ETA: 1s - loss: 1.5784 - acc: 0.445 - ETA: 1s - loss: 1.5742 - acc: 0.449 - ETA: 1s - loss: 1.5772 - acc: 0.449 - ETA: 1s - loss: 1.5796 - acc: 0.449 - ETA: 1s - loss: 1.5754 - acc: 0.449 - ETA: 1s - loss: 1.5768 - acc: 0.450 - ETA: 1s - loss: 1.5731 - acc: 0.451 - ETA: 1s - loss: 1.5784 - acc: 0.450 - ETA: 1s - loss: 1.5777 - acc: 0.450 - ETA: 1s - loss: 1.5798 - acc: 0.448 - ETA: 1s - loss: 1.5803 - acc: 0.448 - ETA: 1s - loss: 1.5814 - acc: 0.448 - ETA: 1s - loss: 1.5822 - acc: 0.447 - ETA: 1s - loss: 1.5813 - acc: 0.447 - ETA: 0s - loss: 1.5844 - acc: 0.446 - ETA: 0s - loss: 1.5835 - acc: 0.447 - ETA: 0s - loss: 1.5837 - acc: 0.448 - ETA: 0s - loss: 1.5799 - acc: 0.450 - ETA: 0s - loss: 1.5806 - acc: 0.450 - ETA: 0s - loss: 1.5783 - acc: 0.451 - ETA: 0s - loss: 1.5819 - acc: 0.450 - ETA: 0s - loss: 1.5848 - acc: 0.449 - ETA: 0s - loss: 1.5862 - acc: 0.447 - ETA: 0s - loss: 1.5830 - acc: 0.448 - ETA: 0s - loss: 1.5816 - acc: 0.448 - ETA: 0s - loss: 1.5847 - acc: 0.448 - ETA: 0s - loss: 1.5852 - acc: 0.450 - ETA: 0s - loss: 1.5827 - acc: 0.450 - ETA: 0s - loss: 1.5828 - acc: 0.450 - ETA: 0s - loss: 1.5792 - acc: 0.452 - 6s 2ms/step - loss: 1.5790 - acc: 0.4528 - val_loss: 1.6001 - val_acc: 0.4643\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.59879\n",
      "Epoch 4/5\n",
      "3021/3021 [==============================] - ETA: 4s - loss: 1.5073 - acc: 0.500 - ETA: 4s - loss: 1.4591 - acc: 0.466 - ETA: 4s - loss: 1.4331 - acc: 0.510 - ETA: 4s - loss: 1.5190 - acc: 0.457 - ETA: 4s - loss: 1.5239 - acc: 0.455 - ETA: 4s - loss: 1.5129 - acc: 0.450 - ETA: 4s - loss: 1.5266 - acc: 0.457 - ETA: 4s - loss: 1.5508 - acc: 0.450 - ETA: 4s - loss: 1.5536 - acc: 0.447 - ETA: 4s - loss: 1.5412 - acc: 0.468 - ETA: 4s - loss: 1.5386 - acc: 0.464 - ETA: 4s - loss: 1.5389 - acc: 0.463 - ETA: 3s - loss: 1.5415 - acc: 0.464 - ETA: 3s - loss: 1.5531 - acc: 0.455 - ETA: 3s - loss: 1.5542 - acc: 0.456 - ETA: 3s - loss: 1.5669 - acc: 0.453 - ETA: 3s - loss: 1.5698 - acc: 0.454 - ETA: 3s - loss: 1.5676 - acc: 0.451 - ETA: 3s - loss: 1.5691 - acc: 0.448 - ETA: 3s - loss: 1.5612 - acc: 0.452 - ETA: 3s - loss: 1.5556 - acc: 0.456 - ETA: 3s - loss: 1.5559 - acc: 0.458 - ETA: 3s - loss: 1.5556 - acc: 0.457 - ETA: 3s - loss: 1.5646 - acc: 0.450 - ETA: 3s - loss: 1.5688 - acc: 0.449 - ETA: 3s - loss: 1.5723 - acc: 0.449 - ETA: 3s - loss: 1.5712 - acc: 0.450 - ETA: 3s - loss: 1.5723 - acc: 0.448 - ETA: 2s - loss: 1.5741 - acc: 0.447 - ETA: 2s - loss: 1.5720 - acc: 0.446 - ETA: 2s - loss: 1.5687 - acc: 0.445 - ETA: 2s - loss: 1.5693 - acc: 0.446 - ETA: 2s - loss: 1.5717 - acc: 0.446 - ETA: 2s - loss: 1.5712 - acc: 0.447 - ETA: 2s - loss: 1.5781 - acc: 0.444 - ETA: 2s - loss: 1.5826 - acc: 0.442 - ETA: 2s - loss: 1.5757 - acc: 0.447 - ETA: 2s - loss: 1.5773 - acc: 0.445 - ETA: 2s - loss: 1.5751 - acc: 0.446 - ETA: 2s - loss: 1.5653 - acc: 0.452 - ETA: 2s - loss: 1.5706 - acc: 0.450 - ETA: 2s - loss: 1.5715 - acc: 0.450 - ETA: 2s - loss: 1.5741 - acc: 0.450 - ETA: 2s - loss: 1.5749 - acc: 0.450 - ETA: 1s - loss: 1.5697 - acc: 0.451 - ETA: 1s - loss: 1.5690 - acc: 0.451 - ETA: 1s - loss: 1.5687 - acc: 0.452 - ETA: 1s - loss: 1.5699 - acc: 0.452 - ETA: 1s - loss: 1.5724 - acc: 0.450 - ETA: 1s - loss: 1.5750 - acc: 0.450 - ETA: 1s - loss: 1.5721 - acc: 0.454 - ETA: 1s - loss: 1.5739 - acc: 0.453 - ETA: 1s - loss: 1.5741 - acc: 0.452 - ETA: 1s - loss: 1.5708 - acc: 0.453 - ETA: 1s - loss: 1.5705 - acc: 0.452 - ETA: 1s - loss: 1.5733 - acc: 0.452 - ETA: 1s - loss: 1.5747 - acc: 0.452 - ETA: 1s - loss: 1.5757 - acc: 0.451 - ETA: 1s - loss: 1.5725 - acc: 0.452 - ETA: 1s - loss: 1.5710 - acc: 0.450 - ETA: 0s - loss: 1.5698 - acc: 0.450 - ETA: 0s - loss: 1.5655 - acc: 0.452 - ETA: 0s - loss: 1.5660 - acc: 0.450 - ETA: 0s - loss: 1.5668 - acc: 0.451 - ETA: 0s - loss: 1.5663 - acc: 0.452 - ETA: 0s - loss: 1.5674 - acc: 0.453 - ETA: 0s - loss: 1.5710 - acc: 0.451 - ETA: 0s - loss: 1.5740 - acc: 0.449 - ETA: 0s - loss: 1.5735 - acc: 0.450 - ETA: 0s - loss: 1.5708 - acc: 0.451 - ETA: 0s - loss: 1.5708 - acc: 0.450 - ETA: 0s - loss: 1.5699 - acc: 0.451 - ETA: 0s - loss: 1.5731 - acc: 0.450 - ETA: 0s - loss: 1.5703 - acc: 0.451 - ETA: 0s - loss: 1.5712 - acc: 0.451 - ETA: 0s - loss: 1.5696 - acc: 0.451 - 5s 2ms/step - loss: 1.5707 - acc: 0.4512 - val_loss: 1.5659 - val_acc: 0.4616\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.59879 to 1.56585, saving model to saved_models/weights.best.benchmark.hdf5\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3021/3021 [==============================] - ETA: 4s - loss: 1.8919 - acc: 0.350 - ETA: 4s - loss: 1.5192 - acc: 0.466 - ETA: 4s - loss: 1.5303 - acc: 0.490 - ETA: 4s - loss: 1.4823 - acc: 0.492 - ETA: 4s - loss: 1.5737 - acc: 0.455 - ETA: 4s - loss: 1.5885 - acc: 0.440 - ETA: 4s - loss: 1.6066 - acc: 0.430 - ETA: 4s - loss: 1.5647 - acc: 0.463 - ETA: 4s - loss: 1.5834 - acc: 0.447 - ETA: 4s - loss: 1.5840 - acc: 0.447 - ETA: 4s - loss: 1.5920 - acc: 0.442 - ETA: 4s - loss: 1.5711 - acc: 0.447 - ETA: 4s - loss: 1.5621 - acc: 0.452 - ETA: 3s - loss: 1.5596 - acc: 0.448 - ETA: 3s - loss: 1.5665 - acc: 0.448 - ETA: 3s - loss: 1.5678 - acc: 0.445 - ETA: 3s - loss: 1.5707 - acc: 0.445 - ETA: 3s - loss: 1.5781 - acc: 0.441 - ETA: 3s - loss: 1.5764 - acc: 0.440 - ETA: 3s - loss: 1.5841 - acc: 0.439 - ETA: 3s - loss: 1.5759 - acc: 0.446 - ETA: 3s - loss: 1.5778 - acc: 0.445 - ETA: 3s - loss: 1.5867 - acc: 0.443 - ETA: 3s - loss: 1.5837 - acc: 0.445 - ETA: 3s - loss: 1.5761 - acc: 0.450 - ETA: 3s - loss: 1.5651 - acc: 0.453 - ETA: 3s - loss: 1.5622 - acc: 0.456 - ETA: 3s - loss: 1.5582 - acc: 0.461 - ETA: 3s - loss: 1.5551 - acc: 0.462 - ETA: 2s - loss: 1.5518 - acc: 0.464 - ETA: 2s - loss: 1.5566 - acc: 0.464 - ETA: 2s - loss: 1.5607 - acc: 0.462 - ETA: 2s - loss: 1.5592 - acc: 0.460 - ETA: 2s - loss: 1.5581 - acc: 0.461 - ETA: 2s - loss: 1.5613 - acc: 0.458 - ETA: 2s - loss: 1.5589 - acc: 0.457 - ETA: 2s - loss: 1.5611 - acc: 0.458 - ETA: 2s - loss: 1.5624 - acc: 0.458 - ETA: 2s - loss: 1.5634 - acc: 0.459 - ETA: 2s - loss: 1.5610 - acc: 0.462 - ETA: 2s - loss: 1.5620 - acc: 0.461 - ETA: 2s - loss: 1.5624 - acc: 0.462 - ETA: 2s - loss: 1.5619 - acc: 0.462 - ETA: 2s - loss: 1.5565 - acc: 0.464 - ETA: 2s - loss: 1.5527 - acc: 0.466 - ETA: 1s - loss: 1.5492 - acc: 0.468 - ETA: 1s - loss: 1.5455 - acc: 0.467 - ETA: 1s - loss: 1.5497 - acc: 0.465 - ETA: 1s - loss: 1.5487 - acc: 0.468 - ETA: 1s - loss: 1.5442 - acc: 0.470 - ETA: 1s - loss: 1.5508 - acc: 0.468 - ETA: 1s - loss: 1.5523 - acc: 0.467 - ETA: 1s - loss: 1.5524 - acc: 0.468 - ETA: 1s - loss: 1.5581 - acc: 0.464 - ETA: 1s - loss: 1.5619 - acc: 0.461 - ETA: 1s - loss: 1.5567 - acc: 0.462 - ETA: 1s - loss: 1.5600 - acc: 0.460 - ETA: 1s - loss: 1.5601 - acc: 0.460 - ETA: 1s - loss: 1.5623 - acc: 0.455 - ETA: 1s - loss: 1.5617 - acc: 0.455 - ETA: 1s - loss: 1.5639 - acc: 0.454 - ETA: 0s - loss: 1.5656 - acc: 0.452 - ETA: 0s - loss: 1.5651 - acc: 0.452 - ETA: 0s - loss: 1.5614 - acc: 0.455 - ETA: 0s - loss: 1.5613 - acc: 0.455 - ETA: 0s - loss: 1.5633 - acc: 0.453 - ETA: 0s - loss: 1.5595 - acc: 0.456 - ETA: 0s - loss: 1.5606 - acc: 0.455 - ETA: 0s - loss: 1.5617 - acc: 0.454 - ETA: 0s - loss: 1.5603 - acc: 0.455 - ETA: 0s - loss: 1.5607 - acc: 0.455 - ETA: 0s - loss: 1.5592 - acc: 0.455 - ETA: 0s - loss: 1.5613 - acc: 0.454 - ETA: 0s - loss: 1.5604 - acc: 0.454 - ETA: 0s - loss: 1.5606 - acc: 0.455 - ETA: 0s - loss: 1.5631 - acc: 0.453 - 6s 2ms/step - loss: 1.5623 - acc: 0.4545 - val_loss: 1.5597 - val_acc: 0.4709\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.56585 to 1.55966, saving model to saved_models/weights.best.benchmark.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21b15dbb978>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "#checkpointer saves the best weights.\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.benchmark.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "benchmark.fit(train_tensors, train_targets, batch_size=20, epochs=epochs, callbacks=[checkpointer], validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the  weights of Benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark.load_weights('saved_models/weights.best.benchmark.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_model_prediction = [benchmark.predict(np.expand_dims(img_tensor, axis=0)) for img_tensor in test_tensors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.45079535 0.05587724 0.03729244 0.0189876  0.06276822 0.06921385\n",
      "  0.04805487 0.25701046]]\n",
      "        ALB       BET       DOL       LAG       NoF     OTHER     SHARK  \\\n",
      "0  0.450795  0.055877  0.037292  0.018988  0.062768  0.069214  0.048055   \n",
      "1  0.511404  0.056213  0.036247  0.021200  0.153273  0.048952  0.018980   \n",
      "2  0.487932  0.058989  0.037338  0.023907  0.181417  0.051531  0.018844   \n",
      "3  0.521431  0.055065  0.036472  0.021376  0.150558  0.046648  0.018196   \n",
      "4  0.500062  0.058069  0.037701  0.022866  0.162161  0.050395  0.019403   \n",
      "\n",
      "        YFT  \n",
      "0  0.257010  \n",
      "1  0.153731  \n",
      "2  0.140043  \n",
      "3  0.150254  \n",
      "4  0.149344  \n"
     ]
    }
   ],
   "source": [
    "#visaulizing the array\n",
    "print(benchmark_model_prediction[:][0])\n",
    "\n",
    "#swapping the axes of the benchmark_model_prediction for easy handling\n",
    "benchmark_model_prediction = np.swapaxes(benchmark_model_prediction,0,1)\n",
    "\n",
    "#creating a pandas dataframe for with benchmark model's prediction\n",
    "df_pred_model1 = pd.DataFrame(benchmark_model_prediction[0][:], columns=['ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'])\n",
    "\n",
    "#first five rows of df_pred_model1 dataframe\n",
    "print(df_pred_model1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_files[0]\n",
    "\n",
    "#extracting relevant name of the image from the full-path of image\n",
    "image_names = [test_files[i][15:] for i in range(len(test_files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjusting the filename of the image to match the submission guidelines\n",
    "for i in range(13153):\n",
    "    if image_names[i][5]=='_':\n",
    "        image_names[i] = \"test_stg2/\" + image_names[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_stg2/image_04056.jpg'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_names[1323]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       image       ALB       BET       DOL       LAG  \\\n",
      "0  test_stg2/image_10973.jpg  0.450795  0.055877  0.037292  0.018988   \n",
      "1  test_stg2/image_00175.jpg  0.511404  0.056213  0.036247  0.021200   \n",
      "2  test_stg2/image_09645.jpg  0.487932  0.058989  0.037338  0.023907   \n",
      "3              img_02920.jpg  0.521431  0.055065  0.036472  0.021376   \n",
      "4  test_stg2/image_09349.jpg  0.500062  0.058069  0.037701  0.022866   \n",
      "\n",
      "        NoF     OTHER     SHARK       YFT  \n",
      "0  0.062768  0.069214  0.048055  0.257010  \n",
      "1  0.153273  0.048952  0.018980  0.153731  \n",
      "2  0.181417  0.051531  0.018844  0.140043  \n",
      "3  0.150558  0.046648  0.018196  0.150254  \n",
      "4  0.162161  0.050395  0.019403  0.149344  \n"
     ]
    }
   ],
   "source": [
    "#adding image names to our dataframe\n",
    "df_pred_model1['image'] = pd.DataFrame(image_names)\n",
    "\n",
    "#reindexing the dataframe\n",
    "df_pred_model1 = df_pred_model1.reindex_axis(['image','ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'], axis=1)\n",
    "\n",
    "#printing the first five rows of dataframe\n",
    "print(df_pred_model1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>ALB</th>\n",
       "      <th>BET</th>\n",
       "      <th>DOL</th>\n",
       "      <th>LAG</th>\n",
       "      <th>NoF</th>\n",
       "      <th>OTHER</th>\n",
       "      <th>SHARK</th>\n",
       "      <th>YFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13143</th>\n",
       "      <td>test_stg2/image_05875.jpg</td>\n",
       "      <td>0.531775</td>\n",
       "      <td>0.052631</td>\n",
       "      <td>0.034860</td>\n",
       "      <td>0.018456</td>\n",
       "      <td>0.124097</td>\n",
       "      <td>0.046492</td>\n",
       "      <td>0.019589</td>\n",
       "      <td>0.172098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13144</th>\n",
       "      <td>test_stg2/image_04374.jpg</td>\n",
       "      <td>0.559931</td>\n",
       "      <td>0.048841</td>\n",
       "      <td>0.033541</td>\n",
       "      <td>0.016460</td>\n",
       "      <td>0.101230</td>\n",
       "      <td>0.041206</td>\n",
       "      <td>0.018837</td>\n",
       "      <td>0.179954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13145</th>\n",
       "      <td>test_stg2/image_07892.jpg</td>\n",
       "      <td>0.490316</td>\n",
       "      <td>0.052723</td>\n",
       "      <td>0.034013</td>\n",
       "      <td>0.018064</td>\n",
       "      <td>0.084012</td>\n",
       "      <td>0.061982</td>\n",
       "      <td>0.034851</td>\n",
       "      <td>0.224040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13146</th>\n",
       "      <td>test_stg2/image_09226.jpg</td>\n",
       "      <td>0.493609</td>\n",
       "      <td>0.054511</td>\n",
       "      <td>0.036720</td>\n",
       "      <td>0.019705</td>\n",
       "      <td>0.100509</td>\n",
       "      <td>0.057565</td>\n",
       "      <td>0.029937</td>\n",
       "      <td>0.207444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13147</th>\n",
       "      <td>test_stg2/image_04860.jpg</td>\n",
       "      <td>0.411585</td>\n",
       "      <td>0.069939</td>\n",
       "      <td>0.043084</td>\n",
       "      <td>0.031220</td>\n",
       "      <td>0.206866</td>\n",
       "      <td>0.067671</td>\n",
       "      <td>0.026554</td>\n",
       "      <td>0.143082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13148</th>\n",
       "      <td>img_07578.jpg</td>\n",
       "      <td>0.546506</td>\n",
       "      <td>0.049609</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>0.016681</td>\n",
       "      <td>0.104926</td>\n",
       "      <td>0.044101</td>\n",
       "      <td>0.020027</td>\n",
       "      <td>0.184629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13149</th>\n",
       "      <td>test_stg2/image_03265.jpg</td>\n",
       "      <td>0.585651</td>\n",
       "      <td>0.042836</td>\n",
       "      <td>0.026847</td>\n",
       "      <td>0.013210</td>\n",
       "      <td>0.115020</td>\n",
       "      <td>0.037383</td>\n",
       "      <td>0.014302</td>\n",
       "      <td>0.164750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13150</th>\n",
       "      <td>test_stg2/image_09846.jpg</td>\n",
       "      <td>0.535845</td>\n",
       "      <td>0.048968</td>\n",
       "      <td>0.029614</td>\n",
       "      <td>0.016144</td>\n",
       "      <td>0.141205</td>\n",
       "      <td>0.046622</td>\n",
       "      <td>0.017479</td>\n",
       "      <td>0.164124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13151</th>\n",
       "      <td>test_stg2/image_10800.jpg</td>\n",
       "      <td>0.523572</td>\n",
       "      <td>0.047661</td>\n",
       "      <td>0.030886</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>0.077169</td>\n",
       "      <td>0.053278</td>\n",
       "      <td>0.029592</td>\n",
       "      <td>0.222429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13152</th>\n",
       "      <td>test_stg2/image_02733.jpg</td>\n",
       "      <td>0.547755</td>\n",
       "      <td>0.047985</td>\n",
       "      <td>0.030611</td>\n",
       "      <td>0.015329</td>\n",
       "      <td>0.116310</td>\n",
       "      <td>0.044577</td>\n",
       "      <td>0.018210</td>\n",
       "      <td>0.179223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image       ALB       BET       DOL       LAG  \\\n",
       "13143  test_stg2/image_05875.jpg  0.531775  0.052631  0.034860  0.018456   \n",
       "13144  test_stg2/image_04374.jpg  0.559931  0.048841  0.033541  0.016460   \n",
       "13145  test_stg2/image_07892.jpg  0.490316  0.052723  0.034013  0.018064   \n",
       "13146  test_stg2/image_09226.jpg  0.493609  0.054511  0.036720  0.019705   \n",
       "13147  test_stg2/image_04860.jpg  0.411585  0.069939  0.043084  0.031220   \n",
       "13148              img_07578.jpg  0.546506  0.049609  0.033520  0.016681   \n",
       "13149  test_stg2/image_03265.jpg  0.585651  0.042836  0.026847  0.013210   \n",
       "13150  test_stg2/image_09846.jpg  0.535845  0.048968  0.029614  0.016144   \n",
       "13151  test_stg2/image_10800.jpg  0.523572  0.047661  0.030886  0.015412   \n",
       "13152  test_stg2/image_02733.jpg  0.547755  0.047985  0.030611  0.015329   \n",
       "\n",
       "            NoF     OTHER     SHARK       YFT  \n",
       "13143  0.124097  0.046492  0.019589  0.172098  \n",
       "13144  0.101230  0.041206  0.018837  0.179954  \n",
       "13145  0.084012  0.061982  0.034851  0.224040  \n",
       "13146  0.100509  0.057565  0.029937  0.207444  \n",
       "13147  0.206866  0.067671  0.026554  0.143082  \n",
       "13148  0.104926  0.044101  0.020027  0.184629  \n",
       "13149  0.115020  0.037383  0.014302  0.164750  \n",
       "13150  0.141205  0.046622  0.017479  0.164124  \n",
       "13151  0.077169  0.053278  0.029592  0.222429  \n",
       "13152  0.116310  0.044577  0.018210  0.179223  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_model1.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  .csv file for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_model1.to_csv('submission1-benchmark.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
