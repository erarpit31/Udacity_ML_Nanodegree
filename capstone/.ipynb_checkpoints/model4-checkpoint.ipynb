{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to load the dataset\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    fish_files = np.array(data['filenames'])\n",
    "    fish_target = np_utils.to_categorical(np.array(data['target']), 8)\n",
    "    return fish_files,fish_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3777 images in training dataset\n",
      "There are 13153 images in the training set\n"
     ]
    }
   ],
   "source": [
    "#let's load the training-data\n",
    "train_files, train_targets = load_dataset('data/train')\n",
    "\n",
    "#let's load the teting-data\n",
    "test_files, _ = load_dataset('data/test')\n",
    "\n",
    "#print the number of samples in test and trainin sets\n",
    "print (\"There are %d images in training dataset\"%len(train_files))\n",
    "print (\"There are %d images in the training set\"%len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "\n",
    "#converting image to tensor\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image\n",
    "    img = image.load_img(img_path, target_size=(224,224))\n",
    "    #convering the image to 3-D tensor with shape (224,224,3)\n",
    "    x = image.img_to_array(img)\n",
    "    #convert 3D tensor to 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 13153/13153 [02:09<00:00, 101.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True \n",
    "\n",
    "#preprocessing the data\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3777/3777 [02:28<00:00, 25.49it/s]\n"
     ]
    }
   ],
   "source": [
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3777, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "#shape of the tensor\n",
    "print(np.shape(train_tensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4, Building a new model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 223, 223, 16)      208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 110, 110, 32)      2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 55, 55, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 55, 55, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 54, 54, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 11,064\n",
      "Trainable params: 11,064\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "model4 = Sequential()\n",
    "\n",
    "# model Convolution layer\n",
    "model4.add(Conv2D(filters=16,kernel_size=2,strides=1,activation='relu',input_shape=(224,224,3)))\n",
    "# Max Pooling layer to reduce the dimensionality\n",
    "model4.add(MaxPooling2D(pool_size=2,strides=2))\n",
    "#Dropout layer, for turning off each node with the probability of 0.2\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Conv2D(filters=32, kernel_size=2,strides=1,activation='relu'))\n",
    "model4.add(MaxPooling2D(pool_size=2,strides=2))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Conv2D(filters=64,kernel_size=2,strides=1,activation='relu'))\n",
    "model4.add(MaxPooling2D(pool_size=2,strides=2))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(GlobalAveragePooling2D())\n",
    "#A fully connected dense layer with 8 nodes (no of classes of fish)\n",
    "model4.add(Dense(8,activation='softmax'))\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2643 samples, validate on 1134 samples\n",
      "Epoch 1/10\n",
      "2643/2643 [==============================] - ETA: 18:47 - loss: 2.1536 - acc: 0.05 - ETA: 6:14 - loss: 2.1137 - acc: 0.0833 - ETA: 4:40 - loss: 2.0882 - acc: 0.112 - ETA: 3:44 - loss: 2.0796 - acc: 0.100 - ETA: 3:06 - loss: 2.0615 - acc: 0.116 - ETA: 2:39 - loss: 2.0397 - acc: 0.142 - ETA: 2:19 - loss: 2.0250 - acc: 0.168 - ETA: 2:04 - loss: 2.0161 - acc: 0.183 - ETA: 1:40 - loss: 1.9666 - acc: 0.231 - ETA: 1:32 - loss: 1.9480 - acc: 0.250 - ETA: 1:25 - loss: 1.9162 - acc: 0.276 - ETA: 1:18 - loss: 1.8967 - acc: 0.292 - ETA: 1:13 - loss: 1.8842 - acc: 0.306 - ETA: 1:08 - loss: 1.8627 - acc: 0.321 - ETA: 1:04 - loss: 1.8629 - acc: 0.317 - ETA: 1:00 - loss: 1.8331 - acc: 0.330 - ETA: 57s - loss: 1.8065 - acc: 0.342 - ETA: 54s - loss: 1.8018 - acc: 0.34 - ETA: 51s - loss: 1.7899 - acc: 0.35 - ETA: 49s - loss: 1.7844 - acc: 0.36 - ETA: 46s - loss: 1.7719 - acc: 0.36 - ETA: 44s - loss: 1.7527 - acc: 0.37 - ETA: 42s - loss: 1.7430 - acc: 0.38 - ETA: 40s - loss: 1.7257 - acc: 0.39 - ETA: 37s - loss: 1.7175 - acc: 0.40 - ETA: 34s - loss: 1.7217 - acc: 0.39 - ETA: 32s - loss: 1.7199 - acc: 0.40 - ETA: 30s - loss: 1.7311 - acc: 0.39 - ETA: 29s - loss: 1.7433 - acc: 0.39 - ETA: 28s - loss: 1.7340 - acc: 0.40 - ETA: 28s - loss: 1.7310 - acc: 0.40 - ETA: 27s - loss: 1.7245 - acc: 0.40 - ETA: 26s - loss: 1.7255 - acc: 0.40 - ETA: 25s - loss: 1.7246 - acc: 0.40 - ETA: 23s - loss: 1.7242 - acc: 0.40 - ETA: 22s - loss: 1.7237 - acc: 0.40 - ETA: 21s - loss: 1.7282 - acc: 0.40 - ETA: 21s - loss: 1.7279 - acc: 0.40 - ETA: 20s - loss: 1.7236 - acc: 0.41 - ETA: 19s - loss: 1.7250 - acc: 0.40 - ETA: 18s - loss: 1.7210 - acc: 0.40 - ETA: 17s - loss: 1.7251 - acc: 0.40 - ETA: 16s - loss: 1.7244 - acc: 0.40 - ETA: 16s - loss: 1.7291 - acc: 0.40 - ETA: 16s - loss: 1.7291 - acc: 0.40 - ETA: 15s - loss: 1.7229 - acc: 0.40 - ETA: 15s - loss: 1.7219 - acc: 0.40 - ETA: 14s - loss: 1.7145 - acc: 0.41 - ETA: 14s - loss: 1.7172 - acc: 0.40 - ETA: 13s - loss: 1.7194 - acc: 0.40 - ETA: 13s - loss: 1.7169 - acc: 0.40 - ETA: 13s - loss: 1.7160 - acc: 0.40 - ETA: 12s - loss: 1.7141 - acc: 0.40 - ETA: 12s - loss: 1.7102 - acc: 0.41 - ETA: 11s - loss: 1.7156 - acc: 0.40 - ETA: 11s - loss: 1.7123 - acc: 0.41 - ETA: 11s - loss: 1.7178 - acc: 0.40 - ETA: 11s - loss: 1.7177 - acc: 0.40 - ETA: 10s - loss: 1.7155 - acc: 0.40 - ETA: 10s - loss: 1.7121 - acc: 0.41 - ETA: 10s - loss: 1.7148 - acc: 0.40 - ETA: 10s - loss: 1.7146 - acc: 0.40 - ETA: 9s - loss: 1.7121 - acc: 0.4100 - ETA: 9s - loss: 1.7119 - acc: 0.409 - ETA: 9s - loss: 1.7092 - acc: 0.410 - ETA: 9s - loss: 1.7070 - acc: 0.410 - ETA: 8s - loss: 1.7066 - acc: 0.412 - ETA: 8s - loss: 1.7043 - acc: 0.413 - ETA: 8s - loss: 1.6990 - acc: 0.416 - ETA: 8s - loss: 1.6953 - acc: 0.418 - ETA: 8s - loss: 1.7009 - acc: 0.415 - ETA: 7s - loss: 1.7016 - acc: 0.414 - ETA: 7s - loss: 1.7002 - acc: 0.415 - ETA: 7s - loss: 1.6953 - acc: 0.418 - ETA: 7s - loss: 1.6925 - acc: 0.419 - ETA: 7s - loss: 1.6945 - acc: 0.418 - ETA: 7s - loss: 1.6930 - acc: 0.419 - ETA: 6s - loss: 1.6947 - acc: 0.419 - ETA: 6s - loss: 1.6918 - acc: 0.420 - ETA: 6s - loss: 1.6895 - acc: 0.421 - ETA: 6s - loss: 1.6871 - acc: 0.421 - ETA: 6s - loss: 1.6837 - acc: 0.424 - ETA: 5s - loss: 1.6849 - acc: 0.423 - ETA: 5s - loss: 1.6839 - acc: 0.422 - ETA: 5s - loss: 1.6843 - acc: 0.422 - ETA: 5s - loss: 1.6821 - acc: 0.423 - ETA: 5s - loss: 1.6788 - acc: 0.424 - ETA: 4s - loss: 1.6765 - acc: 0.426 - ETA: 4s - loss: 1.6762 - acc: 0.427 - ETA: 4s - loss: 1.6734 - acc: 0.429 - ETA: 4s - loss: 1.6738 - acc: 0.430 - ETA: 4s - loss: 1.6728 - acc: 0.431 - ETA: 3s - loss: 1.6702 - acc: 0.431 - ETA: 3s - loss: 1.6721 - acc: 0.431 - ETA: 3s - loss: 1.6749 - acc: 0.431 - ETA: 3s - loss: 1.6704 - acc: 0.433 - ETA: 3s - loss: 1.6700 - acc: 0.433 - ETA: 3s - loss: 1.6737 - acc: 0.431 - ETA: 2s - loss: 1.6714 - acc: 0.432 - ETA: 2s - loss: 1.6726 - acc: 0.431 - ETA: 2s - loss: 1.6713 - acc: 0.431 - ETA: 2s - loss: 1.6713 - acc: 0.431 - ETA: 2s - loss: 1.6707 - acc: 0.431 - ETA: 2s - loss: 1.6699 - acc: 0.432 - ETA: 2s - loss: 1.6682 - acc: 0.433 - ETA: 1s - loss: 1.6645 - acc: 0.435 - ETA: 1s - loss: 1.6591 - acc: 0.438 - ETA: 1s - loss: 1.6547 - acc: 0.439 - ETA: 0s - loss: 1.6490 - acc: 0.442 - ETA: 0s - loss: 1.6475 - acc: 0.443 - ETA: 0s - loss: 1.6471 - acc: 0.443 - ETA: 0s - loss: 1.6498 - acc: 0.442 - ETA: 0s - loss: 1.6535 - acc: 0.441 - ETA: 0s - loss: 1.6533 - acc: 0.441 - ETA: 0s - loss: 1.6472 - acc: 0.443 - 20s 7ms/step - loss: 1.6466 - acc: 0.4442 - val_loss: 1.6191 - val_acc: 0.4418\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.61914, saving model to saved_models/weights.best.from_scratch_6.hdf5\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2643/2643 [==============================] - ETA: 4s - loss: 1.6016 - acc: 0.400 - ETA: 4s - loss: 1.7203 - acc: 0.433 - ETA: 5s - loss: 1.7952 - acc: 0.425 - ETA: 6s - loss: 1.7460 - acc: 0.450 - ETA: 6s - loss: 1.7492 - acc: 0.441 - ETA: 6s - loss: 1.7105 - acc: 0.442 - ETA: 6s - loss: 1.6916 - acc: 0.438 - ETA: 6s - loss: 1.6359 - acc: 0.459 - ETA: 6s - loss: 1.6261 - acc: 0.470 - ETA: 6s - loss: 1.6284 - acc: 0.469 - ETA: 5s - loss: 1.6007 - acc: 0.486 - ETA: 5s - loss: 1.5858 - acc: 0.488 - ETA: 5s - loss: 1.5844 - acc: 0.488 - ETA: 5s - loss: 1.5727 - acc: 0.492 - ETA: 5s - loss: 1.5798 - acc: 0.487 - ETA: 5s - loss: 1.5973 - acc: 0.481 - ETA: 5s - loss: 1.5930 - acc: 0.480 - ETA: 5s - loss: 1.5878 - acc: 0.483 - ETA: 5s - loss: 1.5909 - acc: 0.480 - ETA: 5s - loss: 1.5806 - acc: 0.483 - ETA: 5s - loss: 1.5653 - acc: 0.487 - ETA: 5s - loss: 1.5643 - acc: 0.488 - ETA: 5s - loss: 1.5593 - acc: 0.487 - ETA: 5s - loss: 1.5484 - acc: 0.492 - ETA: 5s - loss: 1.5479 - acc: 0.492 - ETA: 5s - loss: 1.5398 - acc: 0.495 - ETA: 5s - loss: 1.5445 - acc: 0.490 - ETA: 4s - loss: 1.5548 - acc: 0.487 - ETA: 4s - loss: 1.5504 - acc: 0.490 - ETA: 4s - loss: 1.5496 - acc: 0.489 - ETA: 4s - loss: 1.5531 - acc: 0.490 - ETA: 4s - loss: 1.5554 - acc: 0.488 - ETA: 4s - loss: 1.5641 - acc: 0.481 - ETA: 4s - loss: 1.5675 - acc: 0.480 - ETA: 4s - loss: 1.5738 - acc: 0.477 - ETA: 4s - loss: 1.5737 - acc: 0.480 - ETA: 4s - loss: 1.5721 - acc: 0.481 - ETA: 4s - loss: 1.5763 - acc: 0.478 - ETA: 4s - loss: 1.5736 - acc: 0.481 - ETA: 4s - loss: 1.5718 - acc: 0.483 - ETA: 4s - loss: 1.5747 - acc: 0.481 - ETA: 4s - loss: 1.5772 - acc: 0.480 - ETA: 4s - loss: 1.5784 - acc: 0.478 - ETA: 3s - loss: 1.5869 - acc: 0.476 - ETA: 3s - loss: 1.5900 - acc: 0.474 - ETA: 3s - loss: 1.5906 - acc: 0.473 - ETA: 3s - loss: 1.5893 - acc: 0.473 - ETA: 3s - loss: 1.5878 - acc: 0.472 - ETA: 3s - loss: 1.5864 - acc: 0.473 - ETA: 3s - loss: 1.5839 - acc: 0.474 - ETA: 3s - loss: 1.5836 - acc: 0.472 - ETA: 3s - loss: 1.5822 - acc: 0.473 - ETA: 3s - loss: 1.5810 - acc: 0.474 - ETA: 3s - loss: 1.5793 - acc: 0.477 - ETA: 3s - loss: 1.5763 - acc: 0.479 - ETA: 3s - loss: 1.5759 - acc: 0.479 - ETA: 3s - loss: 1.5845 - acc: 0.475 - ETA: 3s - loss: 1.5844 - acc: 0.476 - ETA: 3s - loss: 1.5894 - acc: 0.473 - ETA: 3s - loss: 1.5895 - acc: 0.473 - ETA: 2s - loss: 1.5885 - acc: 0.473 - ETA: 2s - loss: 1.5875 - acc: 0.472 - ETA: 2s - loss: 1.5860 - acc: 0.470 - ETA: 2s - loss: 1.5859 - acc: 0.470 - ETA: 2s - loss: 1.5892 - acc: 0.468 - ETA: 2s - loss: 1.5911 - acc: 0.466 - ETA: 2s - loss: 1.5915 - acc: 0.465 - ETA: 2s - loss: 1.5946 - acc: 0.464 - ETA: 2s - loss: 1.5929 - acc: 0.465 - ETA: 2s - loss: 1.5916 - acc: 0.464 - ETA: 2s - loss: 1.5910 - acc: 0.466 - ETA: 2s - loss: 1.5926 - acc: 0.465 - ETA: 2s - loss: 1.5907 - acc: 0.466 - ETA: 2s - loss: 1.5912 - acc: 0.465 - ETA: 2s - loss: 1.5904 - acc: 0.466 - ETA: 2s - loss: 1.5869 - acc: 0.467 - ETA: 1s - loss: 1.5836 - acc: 0.467 - ETA: 1s - loss: 1.5842 - acc: 0.464 - ETA: 1s - loss: 1.5859 - acc: 0.463 - ETA: 1s - loss: 1.5846 - acc: 0.463 - ETA: 1s - loss: 1.5866 - acc: 0.460 - ETA: 1s - loss: 1.5832 - acc: 0.462 - ETA: 1s - loss: 1.5841 - acc: 0.462 - ETA: 1s - loss: 1.5799 - acc: 0.464 - ETA: 1s - loss: 1.5776 - acc: 0.464 - ETA: 1s - loss: 1.5728 - acc: 0.467 - ETA: 1s - loss: 1.5745 - acc: 0.466 - ETA: 0s - loss: 1.5704 - acc: 0.467 - ETA: 0s - loss: 1.5673 - acc: 0.468 - ETA: 0s - loss: 1.5680 - acc: 0.468 - ETA: 0s - loss: 1.5703 - acc: 0.467 - ETA: 0s - loss: 1.5725 - acc: 0.466 - ETA: 0s - loss: 1.5690 - acc: 0.467 - ETA: 0s - loss: 1.5663 - acc: 0.468 - ETA: 0s - loss: 1.5656 - acc: 0.469 - ETA: 0s - loss: 1.5686 - acc: 0.467 - ETA: 0s - loss: 1.5702 - acc: 0.466 - ETA: 0s - loss: 1.5707 - acc: 0.465 - ETA: 0s - loss: 1.5721 - acc: 0.464 - ETA: 0s - loss: 1.5715 - acc: 0.465 - ETA: 0s - loss: 1.5709 - acc: 0.464 - ETA: 0s - loss: 1.5725 - acc: 0.463 - ETA: 0s - loss: 1.5785 - acc: 0.462 - ETA: 0s - loss: 1.5799 - acc: 0.461 - 9s 3ms/step - loss: 1.5804 - acc: 0.4612 - val_loss: 1.6830 - val_acc: 0.4515\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.61914\n",
      "Epoch 00002: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x200ed5546a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "#checkpointer saves the weight of the best model only\n",
    "checkpointer_4 = [EarlyStopping(monitor='val_loss',min_delta=0.01, patience=0, verbose=1), ModelCheckpoint(filepath='saved_models/weights.best.from_scratch_6.hdf5',\n",
    "                                  verbose=1, save_best_only=True)]\n",
    "\n",
    "model4.fit(train_tensors, train_targets, batch_size=20, epochs=epochs, callbacks=checkpointer_4, validation_split=0.3, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for Model-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the  weights of Benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the weights of pretrained model\n",
    "model4.load_weights('saved_models/weights.best.from_scratch_6.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making predictions\n",
    "model4_prediction = [model4.predict(np.expand_dims(img_tensor, axis=0)) for img_tensor in test_tensors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#swapping the axes of the model4_prediction for easy handling\n",
    "model4_prediction = np.swapaxes(model4_prediction,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#creating a pandas dataframe for with benchmark model's prediction\n",
    "df_pred_model4 = pd.DataFrame(model4_prediction[0][:], columns=['ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_files[0]\n",
    "\n",
    "#extracting relevant name of the image from the full-path of image\n",
    "image_names = [test_files[i][15:] for i in range(len(test_files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjusting the filename of the image to match the submission guidelines\n",
    "for i in range(13153):\n",
    "    if image_names[i][5]=='_':\n",
    "        image_names[i] = \"test_stg2/\" + image_names[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#adding image names to our dataframe\n",
    "df_pred_model4['image'] = pd.DataFrame(image_names)\n",
    "\n",
    "#reindexing the dataframe\n",
    "df_pred_model4 = df_pred_model4.reindex_axis(['image','ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>ALB</th>\n",
       "      <th>BET</th>\n",
       "      <th>DOL</th>\n",
       "      <th>LAG</th>\n",
       "      <th>NoF</th>\n",
       "      <th>OTHER</th>\n",
       "      <th>SHARK</th>\n",
       "      <th>YFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13143</th>\n",
       "      <td>test_stg2/image_05875.jpg</td>\n",
       "      <td>0.415886</td>\n",
       "      <td>0.073814</td>\n",
       "      <td>0.043784</td>\n",
       "      <td>0.027284</td>\n",
       "      <td>0.133212</td>\n",
       "      <td>0.073894</td>\n",
       "      <td>0.054015</td>\n",
       "      <td>0.178109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13144</th>\n",
       "      <td>test_stg2/image_04374.jpg</td>\n",
       "      <td>0.415813</td>\n",
       "      <td>0.074429</td>\n",
       "      <td>0.045242</td>\n",
       "      <td>0.028280</td>\n",
       "      <td>0.131970</td>\n",
       "      <td>0.074441</td>\n",
       "      <td>0.054695</td>\n",
       "      <td>0.175129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13145</th>\n",
       "      <td>test_stg2/image_07892.jpg</td>\n",
       "      <td>0.375669</td>\n",
       "      <td>0.080334</td>\n",
       "      <td>0.051132</td>\n",
       "      <td>0.033156</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.085044</td>\n",
       "      <td>0.065447</td>\n",
       "      <td>0.181945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13146</th>\n",
       "      <td>test_stg2/image_09226.jpg</td>\n",
       "      <td>0.378913</td>\n",
       "      <td>0.079869</td>\n",
       "      <td>0.051032</td>\n",
       "      <td>0.033419</td>\n",
       "      <td>0.133085</td>\n",
       "      <td>0.083235</td>\n",
       "      <td>0.062722</td>\n",
       "      <td>0.177724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13147</th>\n",
       "      <td>test_stg2/image_04860.jpg</td>\n",
       "      <td>0.334014</td>\n",
       "      <td>0.087750</td>\n",
       "      <td>0.059643</td>\n",
       "      <td>0.043526</td>\n",
       "      <td>0.152572</td>\n",
       "      <td>0.090438</td>\n",
       "      <td>0.066589</td>\n",
       "      <td>0.165467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13148</th>\n",
       "      <td>img_07578.jpg</td>\n",
       "      <td>0.415816</td>\n",
       "      <td>0.073692</td>\n",
       "      <td>0.044443</td>\n",
       "      <td>0.027745</td>\n",
       "      <td>0.132602</td>\n",
       "      <td>0.074346</td>\n",
       "      <td>0.054310</td>\n",
       "      <td>0.177046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13149</th>\n",
       "      <td>test_stg2/image_03265.jpg</td>\n",
       "      <td>0.453951</td>\n",
       "      <td>0.066238</td>\n",
       "      <td>0.037801</td>\n",
       "      <td>0.022268</td>\n",
       "      <td>0.129926</td>\n",
       "      <td>0.067077</td>\n",
       "      <td>0.046670</td>\n",
       "      <td>0.176069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13150</th>\n",
       "      <td>test_stg2/image_09846.jpg</td>\n",
       "      <td>0.436525</td>\n",
       "      <td>0.068762</td>\n",
       "      <td>0.039430</td>\n",
       "      <td>0.023986</td>\n",
       "      <td>0.134891</td>\n",
       "      <td>0.070251</td>\n",
       "      <td>0.048629</td>\n",
       "      <td>0.177526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13151</th>\n",
       "      <td>test_stg2/image_10800.jpg</td>\n",
       "      <td>0.398119</td>\n",
       "      <td>0.076463</td>\n",
       "      <td>0.046969</td>\n",
       "      <td>0.029355</td>\n",
       "      <td>0.124119</td>\n",
       "      <td>0.080310</td>\n",
       "      <td>0.060930</td>\n",
       "      <td>0.183735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13152</th>\n",
       "      <td>test_stg2/image_02733.jpg</td>\n",
       "      <td>0.439976</td>\n",
       "      <td>0.068481</td>\n",
       "      <td>0.038725</td>\n",
       "      <td>0.023016</td>\n",
       "      <td>0.128799</td>\n",
       "      <td>0.069203</td>\n",
       "      <td>0.049439</td>\n",
       "      <td>0.182360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image       ALB       BET       DOL       LAG  \\\n",
       "13143  test_stg2/image_05875.jpg  0.415886  0.073814  0.043784  0.027284   \n",
       "13144  test_stg2/image_04374.jpg  0.415813  0.074429  0.045242  0.028280   \n",
       "13145  test_stg2/image_07892.jpg  0.375669  0.080334  0.051132  0.033156   \n",
       "13146  test_stg2/image_09226.jpg  0.378913  0.079869  0.051032  0.033419   \n",
       "13147  test_stg2/image_04860.jpg  0.334014  0.087750  0.059643  0.043526   \n",
       "13148              img_07578.jpg  0.415816  0.073692  0.044443  0.027745   \n",
       "13149  test_stg2/image_03265.jpg  0.453951  0.066238  0.037801  0.022268   \n",
       "13150  test_stg2/image_09846.jpg  0.436525  0.068762  0.039430  0.023986   \n",
       "13151  test_stg2/image_10800.jpg  0.398119  0.076463  0.046969  0.029355   \n",
       "13152  test_stg2/image_02733.jpg  0.439976  0.068481  0.038725  0.023016   \n",
       "\n",
       "            NoF     OTHER     SHARK       YFT  \n",
       "13143  0.133212  0.073894  0.054015  0.178109  \n",
       "13144  0.131970  0.074441  0.054695  0.175129  \n",
       "13145  0.127273  0.085044  0.065447  0.181945  \n",
       "13146  0.133085  0.083235  0.062722  0.177724  \n",
       "13147  0.152572  0.090438  0.066589  0.165467  \n",
       "13148  0.132602  0.074346  0.054310  0.177046  \n",
       "13149  0.129926  0.067077  0.046670  0.176069  \n",
       "13150  0.134891  0.070251  0.048629  0.177526  \n",
       "13151  0.124119  0.080310  0.060930  0.183735  \n",
       "13152  0.128799  0.069203  0.049439  0.182360  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_model4.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  .csv file for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_model4.to_csv('submission4.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
