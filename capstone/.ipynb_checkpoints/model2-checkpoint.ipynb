{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to load the dataset\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    fish_files = np.array(data['filenames'])\n",
    "    fish_target = np_utils.to_categorical(np.array(data['target']), 8)\n",
    "    return fish_files,fish_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3777 images in training dataset\n",
      "There are 13153 images in the training set\n"
     ]
    }
   ],
   "source": [
    "#let's load the training-data\n",
    "train_files, train_targets = load_dataset('data/train')\n",
    "\n",
    "#let's load the teting-data\n",
    "test_files, _ = load_dataset('data/test')\n",
    "\n",
    "#print the number of samples in test and trainin sets\n",
    "print (\"There are %d images in training dataset\"%len(train_files))\n",
    "print (\"There are %d images in the training set\"%len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "\n",
    "#converting image to tensor\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image\n",
    "    img = image.load_img(img_path, target_size=(224,224))\n",
    "    #convering the image to 3-D tensor with shape (224,224,3)\n",
    "    x = image.img_to_array(img)\n",
    "    #convert 3D tensor to 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 13153/13153 [02:06<00:00, 104.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True \n",
    "\n",
    "#preprocessing the data\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3777/3777 [01:38<00:00, 38.29it/s]\n"
     ]
    }
   ],
   "source": [
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3777, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "#shape of the tensor\"\n",
    "print(np.shape(train_tensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 using transfer learning, Extracted VGG-19 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "\n",
    "#Extracting the weights of VGG19 model pretrained on Imagenet\n",
    "#defing the Input shape\n",
    "input_tensor = Input(shape=(224,224,3))\n",
    "#extracting the weights wof VGG19, without top layers\n",
    "#and MaxPooling as pooling layer\n",
    "base_model = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False, pooling=max)\n",
    "#removing the last layer\n",
    "output = base_model.get_layer(index = -1).output\n",
    "#defining the model\n",
    "VGG19_model2 = Model(base_model.input, output)\n",
    "VGG19_model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting VGG19 features for training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG19_features = [VGG19_model2.predict(np.expand_dims(train_tensor, axis=0)) for train_tensor in train_tensors]\n",
    "\n",
    "VGG19_features_test = [VGG19_model2.predict(np.expand_dims(test_tensor, axis=0)) for test_tensor in test_tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of VGG_19_features: (3777, 1, 7, 7, 512)\n",
      "Shape of VGG_19_features_test: (13153, 1, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "print (\"Shape of VGG_19_features: {0}\".format(np.shape(VGG19_features)))\n",
    "\n",
    "print (\"Shape of VGG_19_features_test: {0}\".format(np.shape(VGG19_features_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of squeezed_VGG19_train: (3777, 7, 7, 512)\n",
      "Shape of squeezed_VGG_19_test: (13153, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "#VGG_19_features having 5 dimensions, so we have to squeeze it to a 4 dim array by removing extra dimension\n",
    "squeezed_VGG19_train = np.squeeze(VGG19_features, axis=1)\n",
    "#squeezing the test features\n",
    "squeezed_VGG19_test = np.squeeze(VGG19_features_test, axis=1)\n",
    "\n",
    "print (\"Shape of squeezed_VGG19_train: {0}\".format(np.shape(squeezed_VGG19_train)))\n",
    "print (\"Shape of squeezed_VGG_19_test: {0}\".format(np.shape(squeezed_VGG19_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_max_pooling2d_1 (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 8200      \n",
      "=================================================================\n",
      "Total params: 533,512\n",
      "Trainable params: 533,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D, GlobalMaxPooling2D, Dense\n",
    "\n",
    "fish_model = Sequential()\n",
    "#adding a GlobalMaxPooling2D layer with with input shape same as the shape of Squeezed_VGG19_train.\n",
    "fish_model.add(GlobalMaxPooling2D(input_shape=squeezed_VGG19_train.shape[1:]))\n",
    "#adding a fully connected dense layer with relu activation function\n",
    "fish_model.add(Dense(1024, activation='relu'))\n",
    "#adding a dense layer with softmax activation function.\n",
    "#no of nodes are same as the number of classes of fish.\n",
    "fish_model.add(Dense(8, activation = 'softmax'))\n",
    "fish_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the model with rmsprop optimizer\n",
    "fish_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2643 samples, validate on 1134 samples\n",
      "Epoch 1/10\n",
      "2643/2643 [==============================] - ETA: 0s - loss: 0.2721 - acc: 0.950 - ETA: 0s - loss: 0.6907 - acc: 0.777 - ETA: 0s - loss: 0.6451 - acc: 0.791 - ETA: 0s - loss: 0.5819 - acc: 0.801 - ETA: 0s - loss: 0.5982 - acc: 0.798 - ETA: 0s - loss: 0.6103 - acc: 0.794 - ETA: 0s - loss: 0.5933 - acc: 0.799 - ETA: 0s - loss: 0.5964 - acc: 0.796 - ETA: 0s - loss: 0.6002 - acc: 0.793 - ETA: 0s - loss: 0.5973 - acc: 0.792 - ETA: 0s - loss: 0.5995 - acc: 0.792 - ETA: 0s - loss: 0.6035 - acc: 0.792 - ETA: 0s - loss: 0.6067 - acc: 0.789 - ETA: 0s - loss: 0.6001 - acc: 0.792 - ETA: 0s - loss: 0.5974 - acc: 0.792 - 1s 348us/step - loss: 0.6011 - acc: 0.7919 - val_loss: 0.9565 - val_acc: 0.6711\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.95650, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "Epoch 2/10\n",
      "2643/2643 [==============================] - ETA: 1s - loss: 0.5834 - acc: 0.800 - ETA: 0s - loss: 0.6114 - acc: 0.788 - ETA: 0s - loss: 0.5708 - acc: 0.807 - ETA: 0s - loss: 0.5826 - acc: 0.796 - ETA: 0s - loss: 0.5510 - acc: 0.805 - ETA: 0s - loss: 0.5721 - acc: 0.804 - ETA: 0s - loss: 0.5726 - acc: 0.800 - ETA: 0s - loss: 0.5452 - acc: 0.811 - ETA: 0s - loss: 0.5478 - acc: 0.810 - ETA: 0s - loss: 0.5548 - acc: 0.808 - ETA: 0s - loss: 0.5502 - acc: 0.811 - ETA: 0s - loss: 0.5533 - acc: 0.806 - ETA: 0s - loss: 0.5438 - acc: 0.808 - ETA: 0s - loss: 0.5392 - acc: 0.807 - ETA: 0s - loss: 0.5341 - acc: 0.810 - 1s 349us/step - loss: 0.5348 - acc: 0.8104 - val_loss: 2.1913 - val_acc: 0.2937\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.95650\n",
      "Epoch 3/10\n",
      "2643/2643 [==============================] - ETA: 0s - loss: 2.1880 - acc: 0.300 - ETA: 0s - loss: 0.6041 - acc: 0.825 - ETA: 0s - loss: 0.5879 - acc: 0.822 - ETA: 0s - loss: 0.5392 - acc: 0.832 - ETA: 0s - loss: 0.4902 - acc: 0.846 - ETA: 0s - loss: 0.4897 - acc: 0.839 - ETA: 0s - loss: 0.4926 - acc: 0.836 - ETA: 0s - loss: 0.4740 - acc: 0.843 - ETA: 0s - loss: 0.4747 - acc: 0.841 - ETA: 0s - loss: 0.4859 - acc: 0.835 - ETA: 0s - loss: 0.4763 - acc: 0.838 - ETA: 0s - loss: 0.4739 - acc: 0.841 - ETA: 0s - loss: 0.4701 - acc: 0.843 - ETA: 0s - loss: 0.4617 - acc: 0.844 - ETA: 0s - loss: 0.4543 - acc: 0.846 - 1s 346us/step - loss: 0.4538 - acc: 0.8464 - val_loss: 1.0450 - val_acc: 0.7055\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.95650\n",
      "Epoch 4/10\n",
      "2643/2643 [==============================] - ETA: 0s - loss: 0.5005 - acc: 0.800 - ETA: 0s - loss: 0.6135 - acc: 0.755 - ETA: 0s - loss: 0.4628 - acc: 0.821 - ETA: 0s - loss: 0.3758 - acc: 0.855 - ETA: 0s - loss: 0.4044 - acc: 0.850 - ETA: 0s - loss: 0.4057 - acc: 0.857 - ETA: 0s - loss: 0.4029 - acc: 0.858 - ETA: 0s - loss: 0.4263 - acc: 0.848 - ETA: 0s - loss: 0.4157 - acc: 0.854 - ETA: 0s - loss: 0.4250 - acc: 0.852 - ETA: 0s - loss: 0.4290 - acc: 0.852 - ETA: 0s - loss: 0.4263 - acc: 0.852 - ETA: 0s - loss: 0.4410 - acc: 0.850 - ETA: 0s - loss: 0.4325 - acc: 0.853 - ETA: 0s - loss: 0.4250 - acc: 0.855 - 1s 345us/step - loss: 0.4253 - acc: 0.8558 - val_loss: 2.0523 - val_acc: 0.4312\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.95650\n",
      "Epoch 5/10\n",
      "2643/2643 [==============================] - ETA: 0s - loss: 1.5380 - acc: 0.500 - ETA: 0s - loss: 0.4894 - acc: 0.827 - ETA: 0s - loss: 0.4450 - acc: 0.855 - ETA: 0s - loss: 0.4520 - acc: 0.853 - ETA: 0s - loss: 0.4019 - acc: 0.871 - ETA: 0s - loss: 0.3795 - acc: 0.877 - ETA: 0s - loss: 0.3846 - acc: 0.872 - ETA: 0s - loss: 0.3663 - acc: 0.878 - ETA: 0s - loss: 0.3847 - acc: 0.871 - ETA: 0s - loss: 0.3858 - acc: 0.871 - ETA: 0s - loss: 0.3816 - acc: 0.873 - ETA: 0s - loss: 0.3744 - acc: 0.876 - ETA: 0s - loss: 0.3797 - acc: 0.873 - ETA: 0s - loss: 0.3818 - acc: 0.872 - ETA: 0s - loss: 0.3801 - acc: 0.871 - 1s 347us/step - loss: 0.3810 - acc: 0.8717 - val_loss: 0.5055 - val_acc: 0.8254\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.95650 to 0.50554, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "Epoch 6/10\n",
      "2643/2643 [==============================] - ETA: 0s - loss: 0.3787 - acc: 0.800 - ETA: 0s - loss: 0.2548 - acc: 0.890 - ETA: 0s - loss: 0.3271 - acc: 0.884 - ETA: 0s - loss: 0.3862 - acc: 0.866 - ETA: 0s - loss: 0.3281 - acc: 0.888 - ETA: 0s - loss: 0.3152 - acc: 0.894 - ETA: 0s - loss: 0.3410 - acc: 0.883 - ETA: 0s - loss: 0.3262 - acc: 0.889 - ETA: 0s - loss: 0.3268 - acc: 0.888 - ETA: 0s - loss: 0.3201 - acc: 0.890 - ETA: 0s - loss: 0.3275 - acc: 0.887 - ETA: 0s - loss: 0.3202 - acc: 0.889 - ETA: 0s - loss: 0.3195 - acc: 0.891 - ETA: 0s - loss: 0.3241 - acc: 0.888 - ETA: 0s - loss: 0.3394 - acc: 0.883 - 1s 360us/step - loss: 0.3361 - acc: 0.8854 - val_loss: 0.4207 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.50554 to 0.42070, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "Epoch 7/10\n",
      "2643/2643 [==============================] - ETA: 1s - loss: 0.0852 - acc: 1.000 - ETA: 0s - loss: 0.2969 - acc: 0.883 - ETA: 0s - loss: 0.2934 - acc: 0.891 - ETA: 0s - loss: 0.3258 - acc: 0.874 - ETA: 0s - loss: 0.3148 - acc: 0.884 - ETA: 0s - loss: 0.3077 - acc: 0.885 - ETA: 0s - loss: 0.3107 - acc: 0.885 - ETA: 0s - loss: 0.3284 - acc: 0.882 - ETA: 0s - loss: 0.3229 - acc: 0.882 - ETA: 0s - loss: 0.3044 - acc: 0.889 - ETA: 0s - loss: 0.3104 - acc: 0.886 - ETA: 0s - loss: 0.3084 - acc: 0.888 - ETA: 0s - loss: 0.3128 - acc: 0.888 - ETA: 0s - loss: 0.3165 - acc: 0.886 - ETA: 0s - loss: 0.3046 - acc: 0.891 - 1s 360us/step - loss: 0.3062 - acc: 0.8903 - val_loss: 1.1694 - val_acc: 0.6146\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.42070\n",
      "Epoch 8/10\n",
      "2643/2643 [==============================] - ETA: 0s - loss: 1.2480 - acc: 0.550 - ETA: 0s - loss: 0.3191 - acc: 0.885 - ETA: 0s - loss: 0.3309 - acc: 0.884 - ETA: 0s - loss: 0.2890 - acc: 0.896 - ETA: 0s - loss: 0.2822 - acc: 0.903 - ETA: 0s - loss: 0.2972 - acc: 0.898 - ETA: 0s - loss: 0.2756 - acc: 0.903 - ETA: 0s - loss: 0.2826 - acc: 0.903 - ETA: 0s - loss: 0.2761 - acc: 0.905 - ETA: 0s - loss: 0.2843 - acc: 0.904 - ETA: 0s - loss: 0.2829 - acc: 0.904 - ETA: 0s - loss: 0.2830 - acc: 0.904 - ETA: 0s - loss: 0.2902 - acc: 0.903 - ETA: 0s - loss: 0.2869 - acc: 0.901 - ETA: 0s - loss: 0.2857 - acc: 0.903 - 1s 360us/step - loss: 0.2827 - acc: 0.9054 - val_loss: 0.4700 - val_acc: 0.8527\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.42070\n",
      "Epoch 9/10\n",
      "2643/2643 [==============================] - ETA: 0s - loss: 0.2482 - acc: 0.950 - ETA: 0s - loss: 0.2653 - acc: 0.910 - ETA: 0s - loss: 0.2314 - acc: 0.928 - ETA: 0s - loss: 0.2918 - acc: 0.908 - ETA: 0s - loss: 0.2744 - acc: 0.914 - ETA: 0s - loss: 0.2597 - acc: 0.920 - ETA: 0s - loss: 0.2888 - acc: 0.909 - ETA: 0s - loss: 0.2746 - acc: 0.911 - ETA: 0s - loss: 0.2624 - acc: 0.915 - ETA: 0s - loss: 0.2594 - acc: 0.916 - ETA: 0s - loss: 0.2528 - acc: 0.920 - ETA: 0s - loss: 0.2606 - acc: 0.914 - ETA: 0s - loss: 0.2619 - acc: 0.914 - ETA: 0s - loss: 0.2604 - acc: 0.917 - ETA: 0s - loss: 0.2546 - acc: 0.919 - 1s 366us/step - loss: 0.2593 - acc: 0.9156 - val_loss: 1.0654 - val_acc: 0.7487\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.42070\n",
      "Epoch 10/10\n",
      "2643/2643 [==============================] - ETA: 0s - loss: 0.6818 - acc: 0.800 - ETA: 0s - loss: 0.1492 - acc: 0.950 - ETA: 0s - loss: 0.2599 - acc: 0.915 - ETA: 0s - loss: 0.2258 - acc: 0.932 - ETA: 0s - loss: 0.2286 - acc: 0.927 - ETA: 0s - loss: 0.2170 - acc: 0.932 - ETA: 0s - loss: 0.2364 - acc: 0.921 - ETA: 0s - loss: 0.2314 - acc: 0.925 - ETA: 0s - loss: 0.2125 - acc: 0.934 - ETA: 0s - loss: 0.2320 - acc: 0.928 - ETA: 0s - loss: 0.2277 - acc: 0.929 - ETA: 0s - loss: 0.2296 - acc: 0.928 - ETA: 0s - loss: 0.2333 - acc: 0.928 - ETA: 0s - loss: 0.2318 - acc: 0.929 - ETA: 0s - loss: 0.2296 - acc: 0.930 - 1s 351us/step - loss: 0.2364 - acc: 0.9281 - val_loss: 0.4563 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.42070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18849ab2908>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training fish_model on the trainig dataset\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#checkpointer for saving only best weights\n",
    "checkpointer_VGG = ModelCheckpoint(filepath='saved_models/weights.best.VGG19.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "fish_model.fit(squeezed_VGG19_train,train_targets,validation_split=0.3,batch_size=20,\n",
    "               epochs=10,callbacks=[checkpointer_VGG],verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for Model-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the  weights of Benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_model.load_weights('saved_models/weights.best.VGG19.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the predictions from fish_model\n",
    "fish_model_prediction = [fish_model.predict(np.expand_dims(feature, axis=0)) for feature in squeezed_VGG19_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.8164302e-01 6.0717302e-04 1.7280490e-05 2.2413282e-05 9.4259111e-03\n",
      "  1.9288070e-03 2.4875710e-03 3.8676704e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(fish_model_prediction[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13153, 1, 8)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(fish_model_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#swapping the axes for better handling\n",
    "fish_model_prediction = np.swapaxes(fish_model_prediction,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#creating a pandas dataframe for with benchmark model's prediction\n",
    "df_pred_fish_model = pd.DataFrame(fish_model_prediction[0][:], columns=['ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ALB       BET           DOL           LAG       NoF     OTHER  \\\n",
      "0  0.826058  0.000039  3.081456e-06  1.138450e-04  0.013480  0.005857   \n",
      "1  0.981643  0.000607  1.728049e-05  2.241328e-05  0.009426  0.001929   \n",
      "2  0.799668  0.000053  2.480575e-05  9.625995e-05  0.195594  0.003104   \n",
      "3  0.999282  0.000030  9.633685e-07  6.915273e-05  0.000335  0.000255   \n",
      "4  0.924001  0.000009  4.823132e-07  3.318170e-07  0.074761  0.000472   \n",
      "\n",
      "          SHARK       YFT  \n",
      "0  2.155311e-05  0.154428  \n",
      "1  2.487571e-03  0.003868  \n",
      "2  4.579341e-05  0.001415  \n",
      "3  1.255303e-09  0.000027  \n",
      "4  8.517122e-05  0.000670  \n"
     ]
    }
   ],
   "source": [
    "print(df_pred_fish_model[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_files[0]\n",
    "\n",
    "#extracting relevant name of the image from the full-path of image\n",
    "image_names = [test_files[i][15:] for i in range(len(test_files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjusting the filename of the image to match the submission guidelines\n",
    "for i in range(13153):\n",
    "    if image_names[i][5]=='_':\n",
    "        image_names[i] = \"test_stg2/\" + image_names[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       image       ALB       BET           DOL           LAG  \\\n",
      "0  test_stg2/image_10973.jpg  0.826058  0.000039  3.081456e-06  1.138450e-04   \n",
      "1  test_stg2/image_00175.jpg  0.981643  0.000607  1.728049e-05  2.241328e-05   \n",
      "2  test_stg2/image_09645.jpg  0.799668  0.000053  2.480575e-05  9.625995e-05   \n",
      "3              img_02920.jpg  0.999282  0.000030  9.633685e-07  6.915273e-05   \n",
      "4  test_stg2/image_09349.jpg  0.924001  0.000009  4.823132e-07  3.318170e-07   \n",
      "\n",
      "        NoF     OTHER         SHARK       YFT  \n",
      "0  0.013480  0.005857  2.155311e-05  0.154428  \n",
      "1  0.009426  0.001929  2.487571e-03  0.003868  \n",
      "2  0.195594  0.003104  4.579341e-05  0.001415  \n",
      "3  0.000335  0.000255  1.255303e-09  0.000027  \n",
      "4  0.074761  0.000472  8.517122e-05  0.000670  \n"
     ]
    }
   ],
   "source": [
    "#adding image names to our dataframe\n",
    "df_pred_fish_model['image'] = pd.DataFrame(image_names)\n",
    "\n",
    "#reindexing the dataframe\n",
    "df_pred_fish_model = df_pred_fish_model.reindex_axis(['image','ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'], axis=1)\n",
    "\n",
    "#printing the first five rows of dataframe\n",
    "print(df_pred_fish_model[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>ALB</th>\n",
       "      <th>BET</th>\n",
       "      <th>DOL</th>\n",
       "      <th>LAG</th>\n",
       "      <th>NoF</th>\n",
       "      <th>OTHER</th>\n",
       "      <th>SHARK</th>\n",
       "      <th>YFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13143</th>\n",
       "      <td>test_stg2/image_05875.jpg</td>\n",
       "      <td>0.912021</td>\n",
       "      <td>2.139378e-07</td>\n",
       "      <td>3.573953e-07</td>\n",
       "      <td>1.752325e-08</td>\n",
       "      <td>0.087614</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>4.643796e-07</td>\n",
       "      <td>0.000359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13144</th>\n",
       "      <td>test_stg2/image_04374.jpg</td>\n",
       "      <td>0.488202</td>\n",
       "      <td>6.991809e-04</td>\n",
       "      <td>1.621282e-04</td>\n",
       "      <td>1.277162e-04</td>\n",
       "      <td>0.219567</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>7.379734e-07</td>\n",
       "      <td>0.287794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13145</th>\n",
       "      <td>test_stg2/image_07892.jpg</td>\n",
       "      <td>0.127718</td>\n",
       "      <td>5.564110e-07</td>\n",
       "      <td>4.340842e-10</td>\n",
       "      <td>1.050562e-09</td>\n",
       "      <td>0.133792</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.480554e-10</td>\n",
       "      <td>0.738486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13146</th>\n",
       "      <td>test_stg2/image_09226.jpg</td>\n",
       "      <td>0.976595</td>\n",
       "      <td>8.894766e-05</td>\n",
       "      <td>2.095772e-04</td>\n",
       "      <td>5.158936e-06</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>1.366547e-06</td>\n",
       "      <td>0.015053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13147</th>\n",
       "      <td>test_stg2/image_04860.jpg</td>\n",
       "      <td>0.951323</td>\n",
       "      <td>8.440098e-04</td>\n",
       "      <td>8.432475e-06</td>\n",
       "      <td>4.594551e-05</td>\n",
       "      <td>0.040608</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>1.667168e-06</td>\n",
       "      <td>0.007076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13148</th>\n",
       "      <td>img_07578.jpg</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>4.056724e-03</td>\n",
       "      <td>4.595753e-02</td>\n",
       "      <td>6.440025e-08</td>\n",
       "      <td>0.006294</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>4.800255e-08</td>\n",
       "      <td>0.940084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13149</th>\n",
       "      <td>test_stg2/image_03265.jpg</td>\n",
       "      <td>0.047379</td>\n",
       "      <td>9.768966e-06</td>\n",
       "      <td>1.163750e-06</td>\n",
       "      <td>2.680112e-06</td>\n",
       "      <td>0.951973</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>9.491364e-07</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13150</th>\n",
       "      <td>test_stg2/image_09846.jpg</td>\n",
       "      <td>0.273156</td>\n",
       "      <td>2.245731e-04</td>\n",
       "      <td>5.897219e-05</td>\n",
       "      <td>1.383662e-05</td>\n",
       "      <td>0.718948</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>4.906206e-05</td>\n",
       "      <td>0.004679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13151</th>\n",
       "      <td>test_stg2/image_10800.jpg</td>\n",
       "      <td>0.717296</td>\n",
       "      <td>5.683791e-04</td>\n",
       "      <td>3.363607e-08</td>\n",
       "      <td>1.123596e-09</td>\n",
       "      <td>0.251141</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>9.802219e-09</td>\n",
       "      <td>0.030992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13152</th>\n",
       "      <td>test_stg2/image_02733.jpg</td>\n",
       "      <td>0.202337</td>\n",
       "      <td>1.552632e-04</td>\n",
       "      <td>2.199913e-05</td>\n",
       "      <td>3.599256e-06</td>\n",
       "      <td>0.792443</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>1.062710e-04</td>\n",
       "      <td>0.003727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image       ALB           BET           DOL  \\\n",
       "13143  test_stg2/image_05875.jpg  0.912021  2.139378e-07  3.573953e-07   \n",
       "13144  test_stg2/image_04374.jpg  0.488202  6.991809e-04  1.621282e-04   \n",
       "13145  test_stg2/image_07892.jpg  0.127718  5.564110e-07  4.340842e-10   \n",
       "13146  test_stg2/image_09226.jpg  0.976595  8.894766e-05  2.095772e-04   \n",
       "13147  test_stg2/image_04860.jpg  0.951323  8.440098e-04  8.432475e-06   \n",
       "13148              img_07578.jpg  0.003271  4.056724e-03  4.595753e-02   \n",
       "13149  test_stg2/image_03265.jpg  0.047379  9.768966e-06  1.163750e-06   \n",
       "13150  test_stg2/image_09846.jpg  0.273156  2.245731e-04  5.897219e-05   \n",
       "13151  test_stg2/image_10800.jpg  0.717296  5.683791e-04  3.363607e-08   \n",
       "13152  test_stg2/image_02733.jpg  0.202337  1.552632e-04  2.199913e-05   \n",
       "\n",
       "                LAG       NoF     OTHER         SHARK       YFT  \n",
       "13143  1.752325e-08  0.087614  0.000005  4.643796e-07  0.000359  \n",
       "13144  1.277162e-04  0.219567  0.003448  7.379734e-07  0.287794  \n",
       "13145  1.050562e-09  0.133792  0.000003  6.480554e-10  0.738486  \n",
       "13146  5.158936e-06  0.001163  0.006884  1.366547e-06  0.015053  \n",
       "13147  4.594551e-05  0.040608  0.000093  1.667168e-06  0.007076  \n",
       "13148  6.440025e-08  0.006294  0.000336  4.800255e-08  0.940084  \n",
       "13149  2.680112e-06  0.951973  0.000233  9.491364e-07  0.000400  \n",
       "13150  1.383662e-05  0.718948  0.002872  4.906206e-05  0.004679  \n",
       "13151  1.123596e-09  0.251141  0.000003  9.802219e-09  0.030992  \n",
       "13152  3.599256e-06  0.792443  0.001206  1.062710e-04  0.003727  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_fish_model.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  .csv file for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_fish_model.to_csv('submission2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Public Score - 1.64077 and Private Score - 4.04953"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
