{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to load the dataset\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    fish_files = np.array(data['filenames'])\n",
    "    fish_target = np_utils.to_categorical(np.array(data['target']), 8)\n",
    "    return fish_files,fish_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3777 images in training dataset\n",
      "There are 13153 images in the training set\n"
     ]
    }
   ],
   "source": [
    "#let's load the training-data\n",
    "train_files, train_targets = load_dataset('data/train')\n",
    "\n",
    "#let's load the teting-data\n",
    "test_files, _ = load_dataset('data/test')\n",
    "\n",
    "#print the number of samples in test and trainin sets\n",
    "print (\"There are %d images in training dataset\"%len(train_files))\n",
    "print (\"There are %d images in the training set\"%len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "\n",
    "#converting image to tensor\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image\n",
    "    img = image.load_img(img_path, target_size=(224,224))\n",
    "    #convering the image to 3-D tensor with shape (224,224,3)\n",
    "    x = image.img_to_array(img)\n",
    "    #convert 3D tensor to 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 13153/13153 [02:09<00:00, 101.20it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True \n",
    "\n",
    "#preprocessing the data\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3777/3777 [01:37<00:00, 42.39it/s]\n"
     ]
    }
   ],
   "source": [
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3777, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "#shape of the tensor\n",
    "print(np.shape(train_tensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-5, Refining Model-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 223, 223, 32)      416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 110, 110, 64)      8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 54, 54, 128)       32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 27, 27, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 27, 27, 128)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 42,600\n",
      "Trainable params: 42,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "model5 = Sequential()\n",
    "\n",
    "#Model architecture.\n",
    "#Convolution layer\n",
    "model5.add(Conv2D(filters=32,kernel_size=2,strides=1,activation='relu',input_shape=(224,224,3)))\n",
    "# Max Pooling layer to reduce the dimensionality\n",
    "model5.add(MaxPooling2D(pool_size=2,strides=2))\n",
    "#Dropout layer, for turning off each node with the probability of 0.5\n",
    "model5.add(Dropout(0.5))\n",
    "model5.add(Conv2D(filters=64, kernel_size=2,strides=1,activation='relu'))\n",
    "model5.add(MaxPooling2D(pool_size=2,strides=2))\n",
    "#Dropout layer, for turning off each node with the probability of 0.4\n",
    "model5.add(Dropout(0.4))\n",
    "model5.add(Conv2D(filters=128,kernel_size=2,strides=1,activation='relu'))\n",
    "model5.add(MaxPooling2D(pool_size=2,strides=2))\n",
    "#Dropout layer, for turning off each node with the probability of 0.2\n",
    "model5.add(Dropout(0.2))\n",
    "#Global Average Pooling layer for object localization\n",
    "model5.add(GlobalAveragePooling2D())\n",
    "#A fully connected dense layer with 8 nodes (no of classes of fish)\n",
    "model5.add(Dense(8,activation='softmax'))\n",
    "#printing the summary of the architecture\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Model-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2643 samples, validate on 1134 samples\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.75660, saving model to saved_models/weights.best.model5.hdf5\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.75660 to 1.70973, saving model to saved_models/weights.best.model5.hdf5\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.70973 to 1.67688, saving model to saved_models/weights.best.model5.hdf5\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.67688 to 1.58472, saving model to saved_models/weights.best.model5.hdf5\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.58472 to 1.56420, saving model to saved_models/weights.best.model5.hdf5\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.56420 to 1.50906, saving model to saved_models/weights.best.model5.hdf5\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.50906\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.50906 to 1.44786, saving model to saved_models/weights.best.model5.hdf5\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.44786\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.44786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d5910ef978>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "#number of epochs\n",
    "epochs = 10\n",
    "batch_size=20\n",
    "#split the training data into training and validation datasets (30% for validation and 70 % for training).\n",
    "validation_split=0.3\n",
    "# print the progress\n",
    "verbose=0.1\n",
    "\n",
    "#checkpointer saves the weight of the best model only\n",
    "checkpointer_5 = ModelCheckpoint(filepath='saved_models/weights.best.model5.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "model5.fit(train_tensors, train_targets, batch_size=batch_size, epochs=epochs, \n",
    "           callbacks=[checkpointer_5], validation_split=validation_split, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for Model-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the  weights of Benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.load_weights('saved_models/weights.best.model5.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5_prediction = [model5.predict(np.expand_dims(img_tensor, axis=0)) for img_tensor in test_tensors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2684233  0.10738349 0.07769796 0.04475707 0.07960093 0.09364016\n",
      "  0.11497399 0.2135231 ]]\n"
     ]
    }
   ],
   "source": [
    "#visaulizing the array\n",
    "print(model5_prediction[:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ALB       BET       DOL       LAG       NoF     OTHER     SHARK  \\\n",
      "0  0.268423  0.107383  0.077698  0.044757  0.079601  0.093640  0.114974   \n",
      "1  0.374453  0.074432  0.053887  0.017832  0.186082  0.065478  0.002076   \n",
      "2  0.354573  0.046298  0.024999  0.031291  0.228334  0.159255  0.001658   \n",
      "3  0.396436  0.076942  0.036188  0.072826  0.132634  0.120565  0.042135   \n",
      "4  0.374415  0.057608  0.033026  0.033885  0.201088  0.130594  0.003302   \n",
      "\n",
      "        YFT  \n",
      "0  0.213523  \n",
      "1  0.225760  \n",
      "2  0.153592  \n",
      "3  0.122275  \n",
      "4  0.166083  \n"
     ]
    }
   ],
   "source": [
    "#swapping the axes of the model4_prediction for easy handling\n",
    "model5_prediction = np.swapaxes(model5_prediction,0,1)\n",
    "\n",
    "#creating a pandas dataframe for with benchmark model's prediction\n",
    "df_pred_model5 = pd.DataFrame(model5_prediction[0][:], columns=['ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'])\n",
    "\n",
    "#first five rows of df_pred_model1 dataframe\n",
    "print(df_pred_model5[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting name of the image form its path\n",
    "image_names = [test_files[i][15:] for i in range(len(test_files))]\n",
    "\n",
    "\n",
    "#adjusting the filename of the image to match the submission guidelines\n",
    "for i in range(13153):\n",
    "    if image_names[i][5]=='_':\n",
    "        image_names[i] = \"test_stg2/\" + image_names[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       image       ALB       BET       DOL       LAG  \\\n",
      "0  test_stg2/image_10973.jpg  0.268423  0.107383  0.077698  0.044757   \n",
      "1  test_stg2/image_00175.jpg  0.374453  0.074432  0.053887  0.017832   \n",
      "2  test_stg2/image_09645.jpg  0.354573  0.046298  0.024999  0.031291   \n",
      "3              img_02920.jpg  0.396436  0.076942  0.036188  0.072826   \n",
      "4  test_stg2/image_09349.jpg  0.374415  0.057608  0.033026  0.033885   \n",
      "\n",
      "        NoF     OTHER     SHARK       YFT  \n",
      "0  0.079601  0.093640  0.114974  0.213523  \n",
      "1  0.186082  0.065478  0.002076  0.225760  \n",
      "2  0.228334  0.159255  0.001658  0.153592  \n",
      "3  0.132634  0.120565  0.042135  0.122275  \n",
      "4  0.201088  0.130594  0.003302  0.166083  \n"
     ]
    }
   ],
   "source": [
    "#adding image names to our dataframe\n",
    "df_pred_model5['image'] = pd.DataFrame(image_names)\n",
    "\n",
    "#reindexing the dataframe\n",
    "df_pred_model5 = df_pred_model5.reindex_axis(['image','ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'], axis=1)\n",
    "\n",
    "#printing the first five rows of dataframe\n",
    "print(df_pred_model5[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  .csv file for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_model5.to_csv('submission5.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Public Score - 1.50961 and Private Score - 1.77940"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
