{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to load the dataset\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    fish_files = np.array(data['filenames'])\n",
    "    fish_target = np_utils.to_categorical(np.array(data['target']), 8)\n",
    "    return fish_files,fish_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3777 images in training dataset\n",
      "There are 13153 images in the training set\n"
     ]
    }
   ],
   "source": [
    "#let's load the training-data\n",
    "train_files, train_targets = load_dataset('data/train')\n",
    "\n",
    "#let's load the teting-data\n",
    "test_files, _ = load_dataset('data/test')\n",
    "\n",
    "#print the number of samples in test and trainin sets\n",
    "print (\"There are %d images in training dataset\"%len(train_files))\n",
    "print (\"There are %d images in the training set\"%len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "\n",
    "#converting image to tensor\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image\n",
    "    img = image.load_img(img_path, target_size=(224,224))\n",
    "    #convering the image to 3-D tensor with shape (224,224,3)\n",
    "    x = image.img_to_array(img)\n",
    "    #convert 3D tensor to 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 13153/13153 [05:26<00:00, 40.64it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True \n",
    "\n",
    "#preprocessing the data\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3777/3777 [01:38<00:00, 38.49it/s]\n"
     ]
    }
   ],
   "source": [
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3777, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "#shape of the tensor\n",
    "print(np.shape(train_tensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4, Building a new model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 223, 223, 16)      208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 110, 110, 32)      2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 55, 55, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 55, 55, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 54, 54, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 11,064\n",
      "Trainable params: 11,064\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "model4 = Sequential()\n",
    "\n",
    "# model Convolution layer\n",
    "model4.add(Conv2D(filters=16,kernel_size=2,strides=1,activation='relu',input_shape=(224,224,3)))\n",
    "# Max Pooling layer to reduce the dimensionality\n",
    "model4.add(MaxPooling2D(pool_size=2,strides=2))\n",
    "#Dropout layer, for turning off each node with the probability of 0.2\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Conv2D(filters=32, kernel_size=2,strides=1,activation='relu'))\n",
    "model4.add(MaxPooling2D(pool_size=2,strides=2))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Conv2D(filters=64,kernel_size=2,strides=1,activation='relu'))\n",
    "model4.add(MaxPooling2D(pool_size=2,strides=2))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(GlobalAveragePooling2D())\n",
    "#A fully connected dense layer with 8 nodes (no of classes of fish)\n",
    "model4.add(Dense(8,activation='softmax'))\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2643 samples, validate on 1134 samples\n",
      "Epoch 1/10\n",
      "2643/2643 [==============================] - ETA: 13:52 - loss: 2.2082 - acc: 0.0000e+ - ETA: 4:36 - loss: 2.1486 - acc: 0.0000e+00 - ETA: 2:44 - loss: 2.1015 - acc: 0.0900    - ETA: 1:57 - loss: 2.0714 - acc: 0.185 - ETA: 1:30 - loss: 2.0436 - acc: 0.227 - ETA: 1:13 - loss: 2.0104 - acc: 0.272 - ETA: 1:01 - loss: 1.9760 - acc: 0.296 - ETA: 53s - loss: 1.9625 - acc: 0.306 - ETA: 46s - loss: 1.9227 - acc: 0.33 - ETA: 41s - loss: 1.9243 - acc: 0.32 - ETA: 37s - loss: 1.9116 - acc: 0.33 - ETA: 33s - loss: 1.8968 - acc: 0.34 - ETA: 30s - loss: 1.8868 - acc: 0.34 - ETA: 28s - loss: 1.8725 - acc: 0.35 - ETA: 25s - loss: 1.8460 - acc: 0.35 - ETA: 24s - loss: 1.8283 - acc: 0.36 - ETA: 22s - loss: 1.8072 - acc: 0.36 - ETA: 20s - loss: 1.7963 - acc: 0.37 - ETA: 19s - loss: 1.7921 - acc: 0.37 - ETA: 18s - loss: 1.7770 - acc: 0.38 - ETA: 17s - loss: 1.7775 - acc: 0.38 - ETA: 16s - loss: 1.7752 - acc: 0.38 - ETA: 15s - loss: 1.7713 - acc: 0.39 - ETA: 14s - loss: 1.7523 - acc: 0.40 - ETA: 13s - loss: 1.7454 - acc: 0.40 - ETA: 12s - loss: 1.7399 - acc: 0.40 - ETA: 12s - loss: 1.7351 - acc: 0.40 - ETA: 11s - loss: 1.7289 - acc: 0.41 - ETA: 10s - loss: 1.7254 - acc: 0.41 - ETA: 10s - loss: 1.7165 - acc: 0.42 - ETA: 9s - loss: 1.7126 - acc: 0.4205 - ETA: 9s - loss: 1.7181 - acc: 0.417 - ETA: 8s - loss: 1.7114 - acc: 0.420 - ETA: 8s - loss: 1.7116 - acc: 0.422 - ETA: 7s - loss: 1.7094 - acc: 0.422 - ETA: 7s - loss: 1.7037 - acc: 0.423 - ETA: 7s - loss: 1.6981 - acc: 0.426 - ETA: 6s - loss: 1.7005 - acc: 0.423 - ETA: 6s - loss: 1.6987 - acc: 0.424 - ETA: 6s - loss: 1.6963 - acc: 0.425 - ETA: 5s - loss: 1.6935 - acc: 0.428 - ETA: 5s - loss: 1.6942 - acc: 0.425 - ETA: 5s - loss: 1.6954 - acc: 0.424 - ETA: 4s - loss: 1.6918 - acc: 0.427 - ETA: 4s - loss: 1.6843 - acc: 0.430 - ETA: 4s - loss: 1.6802 - acc: 0.431 - ETA: 3s - loss: 1.6776 - acc: 0.433 - ETA: 3s - loss: 1.6720 - acc: 0.436 - ETA: 3s - loss: 1.6783 - acc: 0.434 - ETA: 3s - loss: 1.6745 - acc: 0.436 - ETA: 2s - loss: 1.6707 - acc: 0.438 - ETA: 2s - loss: 1.6695 - acc: 0.438 - ETA: 2s - loss: 1.6670 - acc: 0.439 - ETA: 2s - loss: 1.6645 - acc: 0.440 - ETA: 2s - loss: 1.6641 - acc: 0.441 - ETA: 1s - loss: 1.6605 - acc: 0.443 - ETA: 1s - loss: 1.6584 - acc: 0.443 - ETA: 1s - loss: 1.6608 - acc: 0.443 - ETA: 1s - loss: 1.6614 - acc: 0.442 - ETA: 1s - loss: 1.6592 - acc: 0.443 - ETA: 0s - loss: 1.6577 - acc: 0.443 - ETA: 0s - loss: 1.6618 - acc: 0.441 - ETA: 0s - loss: 1.6562 - acc: 0.444 - ETA: 0s - loss: 1.6549 - acc: 0.444 - ETA: 0s - loss: 1.6574 - acc: 0.444 - ETA: 0s - loss: 1.6526 - acc: 0.446 - 12s 4ms/step - loss: 1.6562 - acc: 0.4453 - val_loss: 1.6557 - val_acc: 0.4418\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.65566, saving model to saved_models/weights.best.model4.hdf5\n",
      "Epoch 2/10\n",
      "2643/2643 [==============================] - ETA: 4s - loss: 1.4722 - acc: 0.500 - ETA: 4s - loss: 1.3717 - acc: 0.583 - ETA: 3s - loss: 1.4037 - acc: 0.560 - ETA: 3s - loss: 1.3873 - acc: 0.564 - ETA: 3s - loss: 1.5344 - acc: 0.511 - ETA: 3s - loss: 1.5183 - acc: 0.509 - ETA: 3s - loss: 1.5678 - acc: 0.488 - ETA: 3s - loss: 1.5349 - acc: 0.503 - ETA: 3s - loss: 1.5515 - acc: 0.485 - ETA: 3s - loss: 1.5576 - acc: 0.476 - ETA: 3s - loss: 1.5569 - acc: 0.480 - ETA: 3s - loss: 1.5639 - acc: 0.475 - ETA: 3s - loss: 1.5708 - acc: 0.477 - ETA: 3s - loss: 1.5701 - acc: 0.482 - ETA: 3s - loss: 1.5689 - acc: 0.482 - ETA: 3s - loss: 1.5506 - acc: 0.491 - ETA: 3s - loss: 1.5541 - acc: 0.487 - ETA: 3s - loss: 1.5667 - acc: 0.483 - ETA: 3s - loss: 1.5740 - acc: 0.480 - ETA: 3s - loss: 1.5663 - acc: 0.482 - ETA: 3s - loss: 1.5458 - acc: 0.491 - ETA: 2s - loss: 1.5373 - acc: 0.492 - ETA: 2s - loss: 1.5517 - acc: 0.490 - ETA: 2s - loss: 1.5623 - acc: 0.484 - ETA: 2s - loss: 1.5574 - acc: 0.486 - ETA: 2s - loss: 1.5573 - acc: 0.486 - ETA: 2s - loss: 1.5567 - acc: 0.486 - ETA: 2s - loss: 1.5630 - acc: 0.482 - ETA: 2s - loss: 1.5620 - acc: 0.482 - ETA: 2s - loss: 1.5569 - acc: 0.482 - ETA: 2s - loss: 1.5601 - acc: 0.480 - ETA: 2s - loss: 1.5635 - acc: 0.479 - ETA: 2s - loss: 1.5611 - acc: 0.482 - ETA: 2s - loss: 1.5609 - acc: 0.480 - ETA: 2s - loss: 1.5650 - acc: 0.480 - ETA: 2s - loss: 1.5643 - acc: 0.478 - ETA: 1s - loss: 1.5671 - acc: 0.478 - ETA: 1s - loss: 1.5693 - acc: 0.476 - ETA: 1s - loss: 1.5671 - acc: 0.478 - ETA: 1s - loss: 1.5680 - acc: 0.476 - ETA: 1s - loss: 1.5667 - acc: 0.476 - ETA: 1s - loss: 1.5671 - acc: 0.475 - ETA: 1s - loss: 1.5750 - acc: 0.472 - ETA: 1s - loss: 1.5774 - acc: 0.470 - ETA: 1s - loss: 1.5819 - acc: 0.469 - ETA: 1s - loss: 1.5812 - acc: 0.469 - ETA: 1s - loss: 1.5782 - acc: 0.471 - ETA: 1s - loss: 1.5786 - acc: 0.469 - ETA: 1s - loss: 1.5794 - acc: 0.471 - ETA: 1s - loss: 1.5832 - acc: 0.467 - ETA: 1s - loss: 1.5845 - acc: 0.467 - ETA: 1s - loss: 1.5890 - acc: 0.464 - ETA: 0s - loss: 1.5894 - acc: 0.464 - ETA: 0s - loss: 1.5906 - acc: 0.464 - ETA: 0s - loss: 1.5911 - acc: 0.464 - ETA: 0s - loss: 1.5925 - acc: 0.463 - ETA: 0s - loss: 1.5971 - acc: 0.462 - ETA: 0s - loss: 1.5964 - acc: 0.463 - ETA: 0s - loss: 1.5973 - acc: 0.463 - ETA: 0s - loss: 1.5970 - acc: 0.461 - ETA: 0s - loss: 1.5977 - acc: 0.461 - ETA: 0s - loss: 1.5988 - acc: 0.458 - ETA: 0s - loss: 1.5999 - acc: 0.457 - ETA: 0s - loss: 1.5990 - acc: 0.458 - ETA: 0s - loss: 1.5993 - acc: 0.458 - ETA: 0s - loss: 1.5960 - acc: 0.460 - ETA: 0s - loss: 1.5950 - acc: 0.461 - 5s 2ms/step - loss: 1.5950 - acc: 0.4616 - val_loss: 1.6116 - val_acc: 0.4418\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.65566 to 1.61160, saving model to saved_models/weights.best.model4.hdf5\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2643/2643 [==============================] - ETA: 4s - loss: 1.5246 - acc: 0.450 - ETA: 4s - loss: 1.6381 - acc: 0.400 - ETA: 4s - loss: 1.6687 - acc: 0.390 - ETA: 3s - loss: 1.5810 - acc: 0.442 - ETA: 4s - loss: 1.6280 - acc: 0.422 - ETA: 3s - loss: 1.6125 - acc: 0.436 - ETA: 3s - loss: 1.6409 - acc: 0.423 - ETA: 3s - loss: 1.6416 - acc: 0.440 - ETA: 3s - loss: 1.6592 - acc: 0.435 - ETA: 3s - loss: 1.6416 - acc: 0.439 - ETA: 3s - loss: 1.6498 - acc: 0.435 - ETA: 3s - loss: 1.6619 - acc: 0.426 - ETA: 3s - loss: 1.6521 - acc: 0.424 - ETA: 3s - loss: 1.6498 - acc: 0.422 - ETA: 3s - loss: 1.6586 - acc: 0.419 - ETA: 3s - loss: 1.6617 - acc: 0.421 - ETA: 3s - loss: 1.6629 - acc: 0.421 - ETA: 3s - loss: 1.6580 - acc: 0.421 - ETA: 3s - loss: 1.6405 - acc: 0.427 - ETA: 3s - loss: 1.6359 - acc: 0.432 - ETA: 3s - loss: 1.6369 - acc: 0.436 - ETA: 2s - loss: 1.6357 - acc: 0.434 - ETA: 2s - loss: 1.6350 - acc: 0.436 - ETA: 2s - loss: 1.6263 - acc: 0.436 - ETA: 2s - loss: 1.6238 - acc: 0.438 - ETA: 2s - loss: 1.6088 - acc: 0.447 - ETA: 2s - loss: 1.6011 - acc: 0.450 - ETA: 2s - loss: 1.5961 - acc: 0.452 - ETA: 2s - loss: 1.5942 - acc: 0.450 - ETA: 2s - loss: 1.5922 - acc: 0.452 - ETA: 2s - loss: 1.5938 - acc: 0.453 - ETA: 2s - loss: 1.5916 - acc: 0.454 - ETA: 2s - loss: 1.5900 - acc: 0.457 - ETA: 2s - loss: 1.5849 - acc: 0.459 - ETA: 2s - loss: 1.5810 - acc: 0.461 - ETA: 2s - loss: 1.5872 - acc: 0.459 - ETA: 1s - loss: 1.5864 - acc: 0.459 - ETA: 1s - loss: 1.5848 - acc: 0.459 - ETA: 1s - loss: 1.5804 - acc: 0.460 - ETA: 1s - loss: 1.5778 - acc: 0.460 - ETA: 1s - loss: 1.5747 - acc: 0.461 - ETA: 1s - loss: 1.5725 - acc: 0.464 - ETA: 1s - loss: 1.5772 - acc: 0.459 - ETA: 1s - loss: 1.5683 - acc: 0.462 - ETA: 1s - loss: 1.5685 - acc: 0.461 - ETA: 1s - loss: 1.5698 - acc: 0.460 - ETA: 1s - loss: 1.5714 - acc: 0.460 - ETA: 1s - loss: 1.5710 - acc: 0.460 - ETA: 1s - loss: 1.5729 - acc: 0.458 - ETA: 1s - loss: 1.5760 - acc: 0.455 - ETA: 1s - loss: 1.5732 - acc: 0.455 - ETA: 0s - loss: 1.5716 - acc: 0.457 - ETA: 0s - loss: 1.5713 - acc: 0.458 - ETA: 0s - loss: 1.5693 - acc: 0.459 - ETA: 0s - loss: 1.5747 - acc: 0.456 - ETA: 0s - loss: 1.5686 - acc: 0.459 - ETA: 0s - loss: 1.5680 - acc: 0.459 - ETA: 0s - loss: 1.5728 - acc: 0.458 - ETA: 0s - loss: 1.5718 - acc: 0.458 - ETA: 0s - loss: 1.5688 - acc: 0.460 - ETA: 0s - loss: 1.5712 - acc: 0.458 - ETA: 0s - loss: 1.5695 - acc: 0.459 - ETA: 0s - loss: 1.5708 - acc: 0.459 - ETA: 0s - loss: 1.5714 - acc: 0.460 - ETA: 0s - loss: 1.5699 - acc: 0.460 - ETA: 0s - loss: 1.5688 - acc: 0.461 - ETA: 0s - loss: 1.5694 - acc: 0.461 - 5s 2ms/step - loss: 1.5690 - acc: 0.4612 - val_loss: 1.5743 - val_acc: 0.4577\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.61160 to 1.57431, saving model to saved_models/weights.best.model4.hdf5\n",
      "Epoch 4/10\n",
      "2643/2643 [==============================] - ETA: 3s - loss: 1.7377 - acc: 0.350 - ETA: 3s - loss: 1.5623 - acc: 0.450 - ETA: 3s - loss: 1.5794 - acc: 0.440 - ETA: 3s - loss: 1.6337 - acc: 0.428 - ETA: 3s - loss: 1.6248 - acc: 0.422 - ETA: 3s - loss: 1.5981 - acc: 0.440 - ETA: 3s - loss: 1.5593 - acc: 0.469 - ETA: 3s - loss: 1.5748 - acc: 0.460 - ETA: 3s - loss: 1.5603 - acc: 0.452 - ETA: 3s - loss: 1.5438 - acc: 0.465 - ETA: 3s - loss: 1.5595 - acc: 0.466 - ETA: 3s - loss: 1.5546 - acc: 0.460 - ETA: 3s - loss: 1.5395 - acc: 0.468 - ETA: 3s - loss: 1.5499 - acc: 0.468 - ETA: 3s - loss: 1.5683 - acc: 0.456 - ETA: 3s - loss: 1.5804 - acc: 0.453 - ETA: 3s - loss: 1.5859 - acc: 0.448 - ETA: 3s - loss: 1.5860 - acc: 0.448 - ETA: 2s - loss: 1.5775 - acc: 0.452 - ETA: 2s - loss: 1.5786 - acc: 0.455 - ETA: 2s - loss: 1.5763 - acc: 0.456 - ETA: 2s - loss: 1.5809 - acc: 0.452 - ETA: 2s - loss: 1.5743 - acc: 0.458 - ETA: 2s - loss: 1.5773 - acc: 0.453 - ETA: 2s - loss: 1.5713 - acc: 0.454 - ETA: 2s - loss: 1.5648 - acc: 0.457 - ETA: 2s - loss: 1.5612 - acc: 0.460 - ETA: 2s - loss: 1.5537 - acc: 0.459 - ETA: 2s - loss: 1.5522 - acc: 0.459 - ETA: 2s - loss: 1.5477 - acc: 0.461 - ETA: 2s - loss: 1.5479 - acc: 0.460 - ETA: 2s - loss: 1.5420 - acc: 0.460 - ETA: 2s - loss: 1.5503 - acc: 0.458 - ETA: 2s - loss: 1.5532 - acc: 0.457 - ETA: 2s - loss: 1.5511 - acc: 0.459 - ETA: 2s - loss: 1.5475 - acc: 0.462 - ETA: 1s - loss: 1.5518 - acc: 0.461 - ETA: 1s - loss: 1.5533 - acc: 0.461 - ETA: 1s - loss: 1.5451 - acc: 0.464 - ETA: 1s - loss: 1.5467 - acc: 0.463 - ETA: 1s - loss: 1.5453 - acc: 0.464 - ETA: 1s - loss: 1.5500 - acc: 0.460 - ETA: 1s - loss: 1.5440 - acc: 0.464 - ETA: 1s - loss: 1.5415 - acc: 0.465 - ETA: 1s - loss: 1.5443 - acc: 0.464 - ETA: 1s - loss: 1.5423 - acc: 0.465 - ETA: 1s - loss: 1.5373 - acc: 0.466 - ETA: 1s - loss: 1.5370 - acc: 0.466 - ETA: 1s - loss: 1.5390 - acc: 0.463 - ETA: 1s - loss: 1.5413 - acc: 0.463 - ETA: 1s - loss: 1.5395 - acc: 0.465 - ETA: 1s - loss: 1.5385 - acc: 0.466 - ETA: 0s - loss: 1.5410 - acc: 0.464 - ETA: 0s - loss: 1.5438 - acc: 0.463 - ETA: 0s - loss: 1.5477 - acc: 0.463 - ETA: 0s - loss: 1.5499 - acc: 0.463 - ETA: 0s - loss: 1.5450 - acc: 0.466 - ETA: 0s - loss: 1.5430 - acc: 0.466 - ETA: 0s - loss: 1.5432 - acc: 0.466 - ETA: 0s - loss: 1.5445 - acc: 0.466 - ETA: 0s - loss: 1.5389 - acc: 0.469 - ETA: 0s - loss: 1.5387 - acc: 0.470 - ETA: 0s - loss: 1.5357 - acc: 0.469 - ETA: 0s - loss: 1.5319 - acc: 0.472 - ETA: 0s - loss: 1.5341 - acc: 0.471 - ETA: 0s - loss: 1.5323 - acc: 0.471 - ETA: 0s - loss: 1.5325 - acc: 0.471 - ETA: 0s - loss: 1.5342 - acc: 0.471 - 5s 2ms/step - loss: 1.5341 - acc: 0.4711 - val_loss: 1.5523 - val_acc: 0.4656\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.57431 to 1.55226, saving model to saved_models/weights.best.model4.hdf5\n",
      "Epoch 5/10\n",
      "2643/2643 [==============================] - ETA: 3s - loss: 1.4518 - acc: 0.500 - ETA: 3s - loss: 1.5494 - acc: 0.483 - ETA: 3s - loss: 1.5714 - acc: 0.470 - ETA: 3s - loss: 1.4755 - acc: 0.485 - ETA: 3s - loss: 1.5023 - acc: 0.455 - ETA: 3s - loss: 1.4994 - acc: 0.459 - ETA: 3s - loss: 1.5116 - acc: 0.446 - ETA: 3s - loss: 1.5581 - acc: 0.436 - ETA: 3s - loss: 1.5484 - acc: 0.447 - ETA: 3s - loss: 1.5515 - acc: 0.444 - ETA: 3s - loss: 1.5399 - acc: 0.447 - ETA: 3s - loss: 1.5387 - acc: 0.445 - ETA: 3s - loss: 1.5507 - acc: 0.444 - ETA: 3s - loss: 1.5260 - acc: 0.457 - ETA: 3s - loss: 1.5285 - acc: 0.458 - ETA: 3s - loss: 1.5424 - acc: 0.456 - ETA: 3s - loss: 1.5400 - acc: 0.456 - ETA: 3s - loss: 1.5424 - acc: 0.454 - ETA: 3s - loss: 1.5317 - acc: 0.459 - ETA: 3s - loss: 1.5244 - acc: 0.461 - ETA: 2s - loss: 1.5318 - acc: 0.457 - ETA: 2s - loss: 1.5261 - acc: 0.461 - ETA: 2s - loss: 1.5155 - acc: 0.467 - ETA: 2s - loss: 1.5180 - acc: 0.464 - ETA: 2s - loss: 1.5105 - acc: 0.466 - ETA: 2s - loss: 1.5034 - acc: 0.467 - ETA: 2s - loss: 1.5003 - acc: 0.469 - ETA: 2s - loss: 1.5032 - acc: 0.470 - ETA: 2s - loss: 1.5044 - acc: 0.471 - ETA: 2s - loss: 1.5108 - acc: 0.468 - ETA: 2s - loss: 1.5165 - acc: 0.465 - ETA: 2s - loss: 1.5104 - acc: 0.468 - ETA: 2s - loss: 1.5094 - acc: 0.470 - ETA: 2s - loss: 1.5005 - acc: 0.473 - ETA: 2s - loss: 1.4979 - acc: 0.473 - ETA: 1s - loss: 1.4986 - acc: 0.470 - ETA: 1s - loss: 1.5062 - acc: 0.467 - ETA: 1s - loss: 1.5114 - acc: 0.466 - ETA: 1s - loss: 1.5113 - acc: 0.466 - ETA: 1s - loss: 1.5080 - acc: 0.467 - ETA: 1s - loss: 1.5111 - acc: 0.466 - ETA: 1s - loss: 1.5062 - acc: 0.471 - ETA: 1s - loss: 1.5096 - acc: 0.470 - ETA: 1s - loss: 1.5157 - acc: 0.469 - ETA: 1s - loss: 1.5098 - acc: 0.471 - ETA: 1s - loss: 1.5109 - acc: 0.472 - ETA: 1s - loss: 1.5088 - acc: 0.473 - ETA: 1s - loss: 1.5074 - acc: 0.474 - ETA: 1s - loss: 1.5030 - acc: 0.475 - ETA: 1s - loss: 1.5033 - acc: 0.476 - ETA: 0s - loss: 1.5050 - acc: 0.475 - ETA: 0s - loss: 1.5059 - acc: 0.475 - ETA: 0s - loss: 1.5092 - acc: 0.474 - ETA: 0s - loss: 1.5091 - acc: 0.476 - ETA: 0s - loss: 1.5063 - acc: 0.478 - ETA: 0s - loss: 1.5028 - acc: 0.478 - ETA: 0s - loss: 1.5033 - acc: 0.479 - ETA: 0s - loss: 1.5076 - acc: 0.477 - ETA: 0s - loss: 1.5029 - acc: 0.479 - ETA: 0s - loss: 1.5012 - acc: 0.481 - ETA: 0s - loss: 1.5018 - acc: 0.481 - ETA: 0s - loss: 1.5012 - acc: 0.481 - ETA: 0s - loss: 1.5032 - acc: 0.480 - ETA: 0s - loss: 1.5060 - acc: 0.479 - ETA: 0s - loss: 1.5082 - acc: 0.477 - ETA: 0s - loss: 1.5074 - acc: 0.478 - 5s 2ms/step - loss: 1.5054 - acc: 0.4794 - val_loss: 1.5397 - val_acc: 0.4568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss improved from 1.55226 to 1.53973, saving model to saved_models/weights.best.model4.hdf5\n",
      "Epoch 6/10\n",
      "2643/2643 [==============================] - ETA: 3s - loss: 1.6775 - acc: 0.200 - ETA: 3s - loss: 1.5794 - acc: 0.400 - ETA: 4s - loss: 1.5200 - acc: 0.430 - ETA: 3s - loss: 1.4781 - acc: 0.457 - ETA: 3s - loss: 1.4669 - acc: 0.461 - ETA: 3s - loss: 1.5214 - acc: 0.440 - ETA: 3s - loss: 1.5074 - acc: 0.438 - ETA: 3s - loss: 1.4948 - acc: 0.436 - ETA: 3s - loss: 1.4976 - acc: 0.438 - ETA: 3s - loss: 1.4887 - acc: 0.439 - ETA: 3s - loss: 1.4927 - acc: 0.440 - ETA: 3s - loss: 1.4812 - acc: 0.454 - ETA: 3s - loss: 1.4579 - acc: 0.470 - ETA: 3s - loss: 1.4439 - acc: 0.477 - ETA: 3s - loss: 1.4598 - acc: 0.470 - ETA: 3s - loss: 1.4521 - acc: 0.471 - ETA: 3s - loss: 1.4459 - acc: 0.472 - ETA: 3s - loss: 1.4572 - acc: 0.474 - ETA: 3s - loss: 1.4543 - acc: 0.478 - ETA: 2s - loss: 1.4567 - acc: 0.474 - ETA: 2s - loss: 1.4510 - acc: 0.476 - ETA: 2s - loss: 1.4553 - acc: 0.476 - ETA: 2s - loss: 1.4575 - acc: 0.477 - ETA: 2s - loss: 1.4653 - acc: 0.473 - ETA: 2s - loss: 1.4776 - acc: 0.468 - ETA: 2s - loss: 1.4745 - acc: 0.471 - ETA: 2s - loss: 1.4682 - acc: 0.478 - ETA: 2s - loss: 1.4712 - acc: 0.478 - ETA: 2s - loss: 1.4679 - acc: 0.478 - ETA: 2s - loss: 1.4793 - acc: 0.471 - ETA: 2s - loss: 1.4918 - acc: 0.467 - ETA: 2s - loss: 1.4956 - acc: 0.465 - ETA: 2s - loss: 1.4946 - acc: 0.465 - ETA: 2s - loss: 1.4930 - acc: 0.465 - ETA: 2s - loss: 1.4910 - acc: 0.465 - ETA: 1s - loss: 1.4891 - acc: 0.464 - ETA: 1s - loss: 1.4844 - acc: 0.466 - ETA: 1s - loss: 1.4810 - acc: 0.468 - ETA: 1s - loss: 1.4815 - acc: 0.467 - ETA: 1s - loss: 1.4789 - acc: 0.469 - ETA: 1s - loss: 1.4770 - acc: 0.469 - ETA: 1s - loss: 1.4780 - acc: 0.467 - ETA: 1s - loss: 1.4753 - acc: 0.469 - ETA: 1s - loss: 1.4746 - acc: 0.471 - ETA: 1s - loss: 1.4694 - acc: 0.475 - ETA: 1s - loss: 1.4724 - acc: 0.474 - ETA: 1s - loss: 1.4761 - acc: 0.474 - ETA: 1s - loss: 1.4768 - acc: 0.475 - ETA: 1s - loss: 1.4786 - acc: 0.476 - ETA: 1s - loss: 1.4799 - acc: 0.475 - ETA: 0s - loss: 1.4779 - acc: 0.475 - ETA: 0s - loss: 1.4753 - acc: 0.476 - ETA: 0s - loss: 1.4770 - acc: 0.476 - ETA: 0s - loss: 1.4799 - acc: 0.474 - ETA: 0s - loss: 1.4794 - acc: 0.474 - ETA: 0s - loss: 1.4773 - acc: 0.474 - ETA: 0s - loss: 1.4795 - acc: 0.472 - ETA: 0s - loss: 1.4815 - acc: 0.472 - ETA: 0s - loss: 1.4825 - acc: 0.471 - ETA: 0s - loss: 1.4812 - acc: 0.473 - ETA: 0s - loss: 1.4793 - acc: 0.474 - ETA: 0s - loss: 1.4817 - acc: 0.473 - ETA: 0s - loss: 1.4830 - acc: 0.472 - ETA: 0s - loss: 1.4804 - acc: 0.473 - ETA: 0s - loss: 1.4783 - acc: 0.474 - ETA: 0s - loss: 1.4756 - acc: 0.475 - 5s 2ms/step - loss: 1.4775 - acc: 0.4752 - val_loss: 1.4785 - val_acc: 0.4630\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.53973 to 1.47847, saving model to saved_models/weights.best.model4.hdf5\n",
      "Epoch 7/10\n",
      "2643/2643 [==============================] - ETA: 4s - loss: 1.2958 - acc: 0.550 - ETA: 4s - loss: 1.4372 - acc: 0.433 - ETA: 4s - loss: 1.3946 - acc: 0.480 - ETA: 4s - loss: 1.4012 - acc: 0.478 - ETA: 3s - loss: 1.4552 - acc: 0.450 - ETA: 3s - loss: 1.4646 - acc: 0.450 - ETA: 3s - loss: 1.4745 - acc: 0.450 - ETA: 3s - loss: 1.4857 - acc: 0.460 - ETA: 3s - loss: 1.4571 - acc: 0.485 - ETA: 3s - loss: 1.4770 - acc: 0.478 - ETA: 3s - loss: 1.4749 - acc: 0.490 - ETA: 3s - loss: 1.4722 - acc: 0.489 - ETA: 3s - loss: 1.4666 - acc: 0.486 - ETA: 3s - loss: 1.4581 - acc: 0.490 - ETA: 3s - loss: 1.4596 - acc: 0.486 - ETA: 3s - loss: 1.4533 - acc: 0.487 - ETA: 3s - loss: 1.4539 - acc: 0.489 - ETA: 3s - loss: 1.4630 - acc: 0.484 - ETA: 2s - loss: 1.4644 - acc: 0.483 - ETA: 2s - loss: 1.4559 - acc: 0.488 - ETA: 2s - loss: 1.4640 - acc: 0.485 - ETA: 2s - loss: 1.4635 - acc: 0.488 - ETA: 2s - loss: 1.4711 - acc: 0.485 - ETA: 2s - loss: 1.4643 - acc: 0.487 - ETA: 2s - loss: 1.4646 - acc: 0.486 - ETA: 2s - loss: 1.4729 - acc: 0.481 - ETA: 2s - loss: 1.4718 - acc: 0.481 - ETA: 2s - loss: 1.4804 - acc: 0.478 - ETA: 2s - loss: 1.4816 - acc: 0.476 - ETA: 2s - loss: 1.4857 - acc: 0.478 - ETA: 2s - loss: 1.4830 - acc: 0.477 - ETA: 2s - loss: 1.4771 - acc: 0.480 - ETA: 2s - loss: 1.4739 - acc: 0.480 - ETA: 2s - loss: 1.4769 - acc: 0.479 - ETA: 2s - loss: 1.4851 - acc: 0.476 - ETA: 2s - loss: 1.4825 - acc: 0.478 - ETA: 1s - loss: 1.4749 - acc: 0.480 - ETA: 1s - loss: 1.4715 - acc: 0.482 - ETA: 1s - loss: 1.4696 - acc: 0.484 - ETA: 1s - loss: 1.4761 - acc: 0.482 - ETA: 1s - loss: 1.4693 - acc: 0.485 - ETA: 1s - loss: 1.4705 - acc: 0.484 - ETA: 1s - loss: 1.4704 - acc: 0.484 - ETA: 1s - loss: 1.4688 - acc: 0.483 - ETA: 1s - loss: 1.4703 - acc: 0.481 - ETA: 1s - loss: 1.4684 - acc: 0.481 - ETA: 1s - loss: 1.4664 - acc: 0.481 - ETA: 1s - loss: 1.4652 - acc: 0.482 - ETA: 1s - loss: 1.4660 - acc: 0.480 - ETA: 1s - loss: 1.4698 - acc: 0.477 - ETA: 1s - loss: 1.4727 - acc: 0.478 - ETA: 0s - loss: 1.4694 - acc: 0.481 - ETA: 0s - loss: 1.4722 - acc: 0.480 - ETA: 0s - loss: 1.4721 - acc: 0.480 - ETA: 0s - loss: 1.4697 - acc: 0.481 - ETA: 0s - loss: 1.4712 - acc: 0.480 - ETA: 0s - loss: 1.4703 - acc: 0.481 - ETA: 0s - loss: 1.4672 - acc: 0.483 - ETA: 0s - loss: 1.4643 - acc: 0.484 - ETA: 0s - loss: 1.4624 - acc: 0.484 - ETA: 0s - loss: 1.4588 - acc: 0.486 - ETA: 0s - loss: 1.4564 - acc: 0.486 - ETA: 0s - loss: 1.4545 - acc: 0.486 - ETA: 0s - loss: 1.4573 - acc: 0.486 - ETA: 0s - loss: 1.4575 - acc: 0.485 - ETA: 0s - loss: 1.4592 - acc: 0.485 - 5s 2ms/step - loss: 1.4601 - acc: 0.4839 - val_loss: 1.4814 - val_acc: 0.4753\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.47847\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2277ab0b9b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "#checkpointer saves the weight of the best model only\n",
    "checkpointer_4 = [EarlyStopping(monitor='val_loss',min_delta=0.01, patience=0, verbose=1), ModelCheckpoint(filepath='saved_models/weights.best.model4.hdf5',\n",
    "                                  verbose=1, save_best_only=True)]\n",
    "\n",
    "model4.fit(train_tensors, train_targets, batch_size=20, epochs=epochs, callbacks=checkpointer_4, validation_split=0.3, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for Model-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the  weights of Benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the weights of pretrained model\n",
    "model4.load_weights('saved_models/weights.best.model4.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making predictions\n",
    "model4_prediction = [model4.predict(np.expand_dims(img_tensor, axis=0)) for img_tensor in test_tensors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#swapping the axes of the model4_prediction for easy handling\n",
    "model4_prediction = np.swapaxes(model4_prediction,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#creating a pandas dataframe for with benchmark model's prediction\n",
    "df_pred_model4 = pd.DataFrame(model4_prediction[0][:], columns=['ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_files[0]\n",
    "\n",
    "#extracting relevant name of the image from the full-path of image\n",
    "image_names = [test_files[i][15:] for i in range(len(test_files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjusting the filename of the image to match the submission guidelines\n",
    "for i in range(13153):\n",
    "    if image_names[i][5]=='_':\n",
    "        image_names[i] = \"test_stg2/\" + image_names[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#adding image names to our dataframe\n",
    "df_pred_model4['image'] = pd.DataFrame(image_names)\n",
    "\n",
    "#reindexing the dataframe\n",
    "df_pred_model4 = df_pred_model4.reindex_axis(['image','ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>ALB</th>\n",
       "      <th>BET</th>\n",
       "      <th>DOL</th>\n",
       "      <th>LAG</th>\n",
       "      <th>NoF</th>\n",
       "      <th>OTHER</th>\n",
       "      <th>SHARK</th>\n",
       "      <th>YFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13143</th>\n",
       "      <td>test_stg2/image_05875.jpg</td>\n",
       "      <td>0.427824</td>\n",
       "      <td>0.072496</td>\n",
       "      <td>0.059171</td>\n",
       "      <td>0.011158</td>\n",
       "      <td>0.180400</td>\n",
       "      <td>0.024542</td>\n",
       "      <td>0.006113</td>\n",
       "      <td>0.218295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13144</th>\n",
       "      <td>test_stg2/image_04374.jpg</td>\n",
       "      <td>0.400981</td>\n",
       "      <td>0.087192</td>\n",
       "      <td>0.072842</td>\n",
       "      <td>0.018080</td>\n",
       "      <td>0.147266</td>\n",
       "      <td>0.032463</td>\n",
       "      <td>0.013517</td>\n",
       "      <td>0.227660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13145</th>\n",
       "      <td>test_stg2/image_07892.jpg</td>\n",
       "      <td>0.396636</td>\n",
       "      <td>0.071194</td>\n",
       "      <td>0.039691</td>\n",
       "      <td>0.034079</td>\n",
       "      <td>0.095064</td>\n",
       "      <td>0.113421</td>\n",
       "      <td>0.070739</td>\n",
       "      <td>0.179176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13146</th>\n",
       "      <td>test_stg2/image_09226.jpg</td>\n",
       "      <td>0.364504</td>\n",
       "      <td>0.085395</td>\n",
       "      <td>0.065137</td>\n",
       "      <td>0.024323</td>\n",
       "      <td>0.151262</td>\n",
       "      <td>0.061419</td>\n",
       "      <td>0.028545</td>\n",
       "      <td>0.219416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13147</th>\n",
       "      <td>test_stg2/image_04860.jpg</td>\n",
       "      <td>0.229461</td>\n",
       "      <td>0.060167</td>\n",
       "      <td>0.040366</td>\n",
       "      <td>0.014635</td>\n",
       "      <td>0.472447</td>\n",
       "      <td>0.057282</td>\n",
       "      <td>0.004087</td>\n",
       "      <td>0.121556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13148</th>\n",
       "      <td>img_07578.jpg</td>\n",
       "      <td>0.328400</td>\n",
       "      <td>0.081171</td>\n",
       "      <td>0.088251</td>\n",
       "      <td>0.008882</td>\n",
       "      <td>0.195327</td>\n",
       "      <td>0.018240</td>\n",
       "      <td>0.005119</td>\n",
       "      <td>0.274612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13149</th>\n",
       "      <td>test_stg2/image_03265.jpg</td>\n",
       "      <td>0.389653</td>\n",
       "      <td>0.071608</td>\n",
       "      <td>0.063397</td>\n",
       "      <td>0.010416</td>\n",
       "      <td>0.213824</td>\n",
       "      <td>0.023768</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.222071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13150</th>\n",
       "      <td>test_stg2/image_09846.jpg</td>\n",
       "      <td>0.210877</td>\n",
       "      <td>0.058776</td>\n",
       "      <td>0.063438</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>0.419978</td>\n",
       "      <td>0.014641</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.226661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13151</th>\n",
       "      <td>test_stg2/image_10800.jpg</td>\n",
       "      <td>0.422967</td>\n",
       "      <td>0.067524</td>\n",
       "      <td>0.036494</td>\n",
       "      <td>0.034155</td>\n",
       "      <td>0.078930</td>\n",
       "      <td>0.105252</td>\n",
       "      <td>0.081145</td>\n",
       "      <td>0.173533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13152</th>\n",
       "      <td>test_stg2/image_02733.jpg</td>\n",
       "      <td>0.247614</td>\n",
       "      <td>0.067075</td>\n",
       "      <td>0.087595</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.281914</td>\n",
       "      <td>0.009291</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.301382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image       ALB       BET       DOL       LAG  \\\n",
       "13143  test_stg2/image_05875.jpg  0.427824  0.072496  0.059171  0.011158   \n",
       "13144  test_stg2/image_04374.jpg  0.400981  0.087192  0.072842  0.018080   \n",
       "13145  test_stg2/image_07892.jpg  0.396636  0.071194  0.039691  0.034079   \n",
       "13146  test_stg2/image_09226.jpg  0.364504  0.085395  0.065137  0.024323   \n",
       "13147  test_stg2/image_04860.jpg  0.229461  0.060167  0.040366  0.014635   \n",
       "13148              img_07578.jpg  0.328400  0.081171  0.088251  0.008882   \n",
       "13149  test_stg2/image_03265.jpg  0.389653  0.071608  0.063397  0.010416   \n",
       "13150  test_stg2/image_09846.jpg  0.210877  0.058776  0.063438  0.004489   \n",
       "13151  test_stg2/image_10800.jpg  0.422967  0.067524  0.036494  0.034155   \n",
       "13152  test_stg2/image_02733.jpg  0.247614  0.067075  0.087595  0.003842   \n",
       "\n",
       "            NoF     OTHER     SHARK       YFT  \n",
       "13143  0.180400  0.024542  0.006113  0.218295  \n",
       "13144  0.147266  0.032463  0.013517  0.227660  \n",
       "13145  0.095064  0.113421  0.070739  0.179176  \n",
       "13146  0.151262  0.061419  0.028545  0.219416  \n",
       "13147  0.472447  0.057282  0.004087  0.121556  \n",
       "13148  0.195327  0.018240  0.005119  0.274612  \n",
       "13149  0.213824  0.023768  0.005262  0.222071  \n",
       "13150  0.419978  0.014641  0.001140  0.226661  \n",
       "13151  0.078930  0.105252  0.081145  0.173533  \n",
       "13152  0.281914  0.009291  0.001287  0.301382  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_model4.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  .csv file for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_model4.to_csv('submission4.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Public Score - 1.50787 and Private Score - 1.76167"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
